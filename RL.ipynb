{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e08d310",
   "metadata": {},
   "source": [
    "Last modified in March 31, 2024 by Dabin Yang\n",
    "\n",
    "Original code generated by Brown, N.K, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87d1e2",
   "metadata": {},
   "source": [
    "# FEA_SOLVER_GENERAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139050ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'Define the Function that creates the rectangular mesh'\n",
    "from skimage.measure import label\n",
    "def label_( x): return label(x, connectivity=1)\n",
    "def get_zero_label(d, labels):\n",
    "    for i in range(d.shape[0]):\n",
    "        for j in range(d.shape[1]):\n",
    "            if d[i,j]==0:\n",
    "                return labels[i,j]\n",
    "\n",
    "def isolate_largest_group_original(x):\n",
    "    \"\"\"Isolates the largest group. \n",
    "    this original version has problems with periodicity. The v2 version fixes this. \"\"\"\n",
    "    x_original = np.copy(x)    \n",
    "    labels= label_(x)\n",
    "    zerolabel=get_zero_label(x,labels)\n",
    "    group_names = np.unique(labels)      \n",
    "    group_names = [g for g in group_names if g!=zerolabel]   \n",
    "    vols = np.array([(labels==name).sum() for name in group_names])\n",
    "    largestgroup_name = group_names[np.argmax(vols)]    \n",
    "    x = labels == largestgroup_name\n",
    "    x = x.astype(\"int\")\n",
    "    design_ok = np.all(x==x_original)  \n",
    "    return x, design_ok\n",
    "\n",
    "def rectangularmesh(Lx,Ly,ElementsX,ElementsY):\n",
    "    Nx=ElementsX\n",
    "    Ny=ElementsY\n",
    "    xx=np.linspace(0,Lx,ElementsX+1)\n",
    "    yy=np.linspace(0,Ly,ElementsY+1)\n",
    "    nodeCoor=np.zeros(((Nx+1)*(Ny+1),2))\n",
    "    elementNodes=np.zeros((Nx*Ny,4))\n",
    "    for j in range(0,len(yy)):\n",
    "        for i in range(0,len(xx)):\n",
    "            call=(Nx+1)*(j)+i\n",
    "            nodeCoor[call,0]=xx[i]\n",
    "            nodeCoor[call,1]=yy[j]     \n",
    "    for j in range(0,Ny):\n",
    "        for i in range(0,Nx):\n",
    "            d=(Nx)*(j)+i;\n",
    "            elementNodes[d,0]=(Nx+1)*(j)+i\n",
    "            elementNodes[d,1]=(Nx+1)*(j)+i+1\n",
    "            elementNodes[d,2]=(Nx+1)*(j+1)+i+1\n",
    "            elementNodes[d,3]=(Nx+1)*(j+1)+i\n",
    "    return nodeCoor, elementNodes\n",
    "\n",
    "def shapeFunctionQ4(xi,eta):\n",
    "    shape=(1/4)*np.matrix([[(1-xi)*(1-eta)],\n",
    "                           [(1+xi)*(1-eta)],\n",
    "                           [(1+xi)*(1+eta)],\n",
    "                           [(1-xi)*(1+eta)]])\n",
    "    naturalDeriv=(1/4)*np.matrix([[-(1-eta),-(1-xi)],\n",
    "                                  [ (1-eta),-(1+xi)],\n",
    "                                  [ (1+eta), (1+xi)],\n",
    "                                  [-(1+eta), (1-xi)]])\n",
    "    return(shape,naturalDeriv) \n",
    "\n",
    "#-----------------------------------------------\n",
    "'Determine Jacobian Matrix and Inverse of Jacobian'\n",
    "def Jacobian(nodeCoor,naturalDeriv):\n",
    "    JacobianMatrix=np.transpose(nodeCoor)*naturalDeriv\n",
    "    invJacobian=np.linalg.inv(JacobianMatrix)\n",
    "    XYDerivative=naturalDeriv*invJacobian\n",
    "    return(JacobianMatrix,invJacobian,XYDerivative)\n",
    "\n",
    "'Calculation of the System Stiffness Matrix'\n",
    "def formStiffness2D(GDof,TotElements,numberNodes,elementNodes,nodeCoor,materials,rho,thickness,VoidCheck):\n",
    "    \"\"\"Compute Stiffness Matrix and (mass matrix)\n",
    "       for plane stress Q4 elements\"\"\"\n",
    "    stiffness=np.zeros((GDof,GDof))\n",
    "\n",
    "    mass=np.zeros((GDof,GDof))\n",
    "    \n",
    "    '2 by 2 quadrature'\n",
    "    gaussLocations=np.array([[-.577350269189626, -.577350269189626],\n",
    "                             [ .577350269189626, -.577350269189626],\n",
    "                             [ .577350269189626,  .577350269189626],\n",
    "                             [-.577350269189626,  .577350269189626]])\n",
    "    gaussWeights=np.array([[1],[1],[1],[1]])\n",
    "\n",
    "    for e in range(0,TotElements):\n",
    "        indice=(elementNodes[e,:])\n",
    "        indice=indice.astype(int)\n",
    "        elementDof=[]\n",
    "        elementDof=np.append(indice,indice+numberNodes)\n",
    "        ndof=len(indice)\n",
    "        'Shape Functions and Derivatives'\n",
    "    \n",
    "        'Cycle for Gauss Point'\n",
    "        for q in range(0,len(gaussWeights)):\n",
    "            GaussPoint=gaussLocations[q,:]\n",
    "            xi=GaussPoint[0]\n",
    "            eta=GaussPoint[1]\n",
    "            #Determine Shape Functions and Derivatives \n",
    "            sFQ4=shapeFunctionQ4(xi,eta)\n",
    "            naturalDeriv=sFQ4[1]\n",
    "            \n",
    "            #Determine Jacobian\n",
    "            JR=Jacobian(nodeCoor[indice,:],naturalDeriv)\n",
    "            JacobianMatrix=JR[0]\n",
    "            \n",
    "            #invJacobian=JR[1]\n",
    "            XYderivative=JR[2]\n",
    "              #------------------------------------------------\n",
    "            'Create the B matrix'\n",
    "            B=np.zeros((3,2*ndof))\n",
    "            B[0,0:ndof]         =np.transpose(XYderivative[:,0])\n",
    "            B[1,ndof:(2*ndof)]  =np.transpose(XYderivative[:,1])\n",
    "            B[2,0:ndof]         =np.transpose(XYderivative[:,1])\n",
    "            B[2,ndof:(2*ndof)]  =np.transpose(XYderivative[:,0])\n",
    "        \n",
    "              #-------------------------------------------------\n",
    "            'Stiffness matrix'\n",
    "            'Assign Unique Material Properties Depending on Void or Material'\n",
    "            if VoidCheck[e]==1:\n",
    "                E=materials[0,0]\n",
    "                poisson=materials[0,1]\n",
    "            else:\n",
    "                E=materials[1,0]\n",
    "                poisson=materials[1,1]\n",
    "            C=np.matrix([[1,poisson,0], [poisson,1,0],[0,0,(1-poisson)/2]])*(E/(1-(poisson**2)))\n",
    "            Mat1=np.asarray(np.transpose(B)*C*thickness*B*1*np.linalg.det(JacobianMatrix))\n",
    "         \n",
    "\n",
    "            stiffness[np.ix_(elementDof,elementDof)]=stiffness[np.ix_(elementDof,elementDof)]+Mat1\n",
    "            \n",
    "    return(stiffness,mass)\n",
    "def solution(GDof,prescribedDof,stiffness,force):\n",
    "    # Function to find solution in terms of global dispalcements\n",
    "    activeDof=[]\n",
    "    GDof_list=list(range(0,GDof))\n",
    "    for i in GDof_list:\n",
    "        if i not in prescribedDof[0]:\n",
    "            activeDof.append(i)\n",
    "    ActiveStiffness=np.zeros((len(activeDof),len(activeDof)))\n",
    "\n",
    "    ActiveStiffness=stiffness[np.ix_(activeDof,activeDof)]\n",
    "    ActiveForce=np.zeros((len(activeDof),1))\n",
    "    for i in range(0,len(activeDof)):\n",
    "        ActiveForce[i]=force[activeDof[i]]\n",
    "    \n",
    "    #U=cupy.matmul(cupy.linalg.inv(cupy.array(ActiveStiffness)),cupy.array(ActiveForce))\n",
    "    #U=cupy.ndarray.get(U)\n",
    "    U=np.matmul(np.linalg.inv(ActiveStiffness),ActiveForce)\n",
    "    displacements=np.zeros((GDof,1))\n",
    "    displacements[activeDof]=U\n",
    "    return displacements\n",
    "def stresses2D(GDof,TotElements,nodeCoor,numberNodes,displacements,UX,UY,materials,ScaleFactor,VoidCheck,elementNodes):    \n",
    "        gaussLocations=np.array([[-.577350269189626, -.577350269189626],\n",
    "                                 [ .577350269189626, -.577350269189626],\n",
    "                                 [ .577350269189626,  .577350269189626],\n",
    "                                 [-.577350269189626,  .577350269189626]])\n",
    "        gaussWeights=np.array([[1],[1],[1],[1]])\n",
    "        'stresses at nodes'\n",
    "        stress=np.zeros((TotElements,len(elementNodes[0]),3))        \n",
    "        for e in range(0,TotElements):\n",
    "            indice=(elementNodes[e,:])\n",
    "            indice=indice.astype(int)\n",
    "            elementDof=[]\n",
    "            elementDof=np.append(indice,indice+numberNodes)\n",
    "\n",
    "            nn=len(indice)\n",
    "            for q in range(0,len(gaussWeights)):\n",
    "                pt=gaussLocations[q,:]\n",
    "                xi=pt[0]\n",
    "                eta=pt[1]\n",
    "                sFQ4=shapeFunctionQ4(xi,eta)\n",
    "                naturalDeriv=sFQ4[1]\n",
    "                #Determine Jacobian\n",
    "                JR=Jacobian(nodeCoor[indice,:],naturalDeriv)\n",
    "                XYderivative=JR[2]\n",
    "                'Create the B matrix'\n",
    "                B=np.zeros((3,2*nn))\n",
    "                B[0,0:nn]         =np.transpose(XYderivative[:,0])\n",
    "                B[1,nn:(2*nn)]  =np.transpose(XYderivative[:,1])\n",
    "                B[2,0:nn]         =np.transpose(XYderivative[:,1])\n",
    "                B[2,nn:(2*nn)]  =np.transpose(XYderivative[:,0])\n",
    "\n",
    "                'Element Deformation'\n",
    "                #Check to See What Material Properties Should Be Assigned\n",
    "                if VoidCheck[e]==1:\n",
    "                    E=materials[0,0]\n",
    "                    poisson=materials[0,1]\n",
    "                else:\n",
    "                    E=materials[1,0]\n",
    "                    poisson=materials[1,1]\n",
    "                C=np.matrix([[1,poisson,0], [poisson,1,0],[0,0,(1-poisson)/2]])*(E/(1-(poisson**2)))\n",
    "                strain=np.matmul(B,displacements[elementDof])\n",
    "                stress[e,q,:]=np.transpose(np.dot(C,strain))\n",
    "\n",
    "        return(stress)\n",
    "def FEASolve(VoidCheck,Lx,Ly,ElementsX,ElementsY,LC_Nodes,Loaded_Directions,BC_Nodes,Stress):\n",
    "    'Input Linear Material Properties'\n",
    "    materials=np.zeros((2,2))\n",
    "    #Real Material Properties\n",
    "    materials[0,0]=10e9 #Modulus of Elasticity\n",
    "    materials[0,1]=0.3 #Poisson's Ratio\n",
    "    \n",
    "    #Void Material Representation \n",
    "    \"\"\"Taken from: An FEM Analysis with Consideration of Random Void Defects for \n",
    "    Predicting the Mechanical Properties of 3D Braided Composities, Kun Xu and Xiaomei Qian\"\"\"\n",
    "    materials[1,0]=1 #Modulus of Elasticity (1e-6 MPa)\n",
    "    materials[1,1]=0.000001 #Poisson's Ratio\n",
    "    \n",
    "    'Input Desired Loading Condition'\n",
    "    P=5e5#Magnitude\n",
    "    \n",
    "    'Mesh Generation'\n",
    "    TotElements=ElementsX*ElementsY #Total Number of Elements \n",
    "    RectOutput=rectangularmesh(Lx,Ly,ElementsX,ElementsY)\n",
    "    nodeCoor=(RectOutput[0])\n",
    "    elementNodes=(RectOutput[1])\n",
    "    xx=nodeCoor[:,0]\n",
    "    yy=nodeCoor[:,1]\n",
    "    numberNodes=len(xx)\n",
    "    'Global Number of Degrees of Freedom'\n",
    "    GDof=2*numberNodes\n",
    "\n",
    "        #-------------------------------------------------------------------\n",
    "    'Boundary Conditions'\n",
    "    '''This portion can be adjusted in accordance with the necessary boundary\n",
    "    conditions of the given problem'''\n",
    "    \n",
    "    'BC currently set up to limit displacement on Y-Axis with distributed force on X=Lx' \n",
    "    fixedNodeX=list(BC_Nodes)\n",
    "    fixedNodeY=list(BC_Nodes+numberNodes)\n",
    " \n",
    "    prescribedDof=[fixedNodeX+fixedNodeY]\n",
    "    'Input Force Vectors'\n",
    "    #Currently Assuming Distributed load applied at xx=Lx (Tensile Testing)\n",
    "    force=np.zeros((GDof,1))\n",
    "    \n",
    "    \n",
    "    #--------------------------------------------------------\n",
    "    #|                                                      |\n",
    "    #|                                                      |\n",
    "    #|    Apply for Point Load on Bottom Right Corner       |\n",
    "    #|                        |                             |\n",
    "    #|                        v                             |\n",
    "    #--------------------------------------------------------\n",
    "    LD_Count=0\n",
    "    for F in range(0,len(LC_Nodes)):\n",
    "        if F/2==int(F/2) and F/2!=0:\n",
    "            LD_Count+=1\n",
    "        force[int(LC_Nodes[F])]=(P/2)*Loaded_Directions[LD_Count]\n",
    "    FS2D=formStiffness2D(GDof,TotElements,numberNodes,elementNodes,nodeCoor,materials,1,1,VoidCheck)                                                         \n",
    "    stiffness=FS2D[0]\n",
    "    displacements=solution(GDof,prescribedDof,stiffness,force)\n",
    "    UX=np.asarray(np.transpose(displacements[0:numberNodes]))\n",
    "    UY=np.asarray(np.transpose(displacements[numberNodes:GDof]))\n",
    "    MaxDisplacements=displacements.min()\n",
    "    StrainEnergy=np.matmul(np.transpose(displacements),stiffness)\n",
    "    StrainEnergy=np.matmul(StrainEnergy,displacements)\n",
    "    RectOutput=rectangularmesh(Lx,Ly,ElementsX,ElementsY)\n",
    "\n",
    "    if Stress is True:\n",
    "        ScaleFactor=0.1      \n",
    "        StressVal=stresses2D(GDof,TotElements,nodeCoor,numberNodes,displacements,UX,UY,materials,ScaleFactor,VoidCheck,elementNodes)\n",
    "        stress=StressVal\n",
    "        sigmax=stress[:,:,0]\n",
    "        sigmay=stress[:,:,1]\n",
    "        tauxy=stress[:,:,2]\n",
    "    \n",
    "        stressx_node=np.zeros((ElementsX+1,ElementsY+1))\n",
    "        stressy_node=np.zeros((ElementsX+1,ElementsY+1))\n",
    "        stressxy_node=np.zeros((ElementsX+1,ElementsY+1))\n",
    "        stressx_element=np.zeros((ElementsX*ElementsY,1))\n",
    "        stressy_element=np.zeros((ElementsX*ElementsY,1))\n",
    "        stressxy_element=np.zeros((ElementsX*ElementsY,1))\n",
    "    \n",
    "        #stressmat=np.zeros(numberNodes)\n",
    "        Count=0\n",
    "        \n",
    "        for j in range(0,ElementsY):\n",
    "            for i in range(0,ElementsX):\n",
    "                #Change sigmax to sigmay for different stress distribution\n",
    "                stressx_node[np.ix_(range(i,i+2),range(j,j+2))]=np.reshape(sigmax[Count,:],(2,2))\n",
    "                stressy_node[np.ix_(range(i,i+2),range(j,j+2))]=np.reshape(sigmay[Count,:],(2,2))\n",
    "                stressxy_node[np.ix_(range(i,i+2),range(j,j+2))]=np.reshape(tauxy[Count,:],(2,2))\n",
    "                Count=Count+1\n",
    "        for ii in range(0,len(stressx_element)):\n",
    "            stressx_element[ii]=np.mean(sigmax[ii,:])\n",
    "            stressy_element[ii]=np.mean(sigmay[ii,:])\n",
    "            stressxy_element[ii]=np.mean(tauxy[ii,:])\n",
    "       \n",
    "        stressx_element=np.reshape(stressx_element,(ElementsX,ElementsY))\n",
    "        stressy_element=np.reshape(stressy_element,(ElementsX,ElementsY))\n",
    "        stressxy_element=np.reshape(stressxy_element,(ElementsX,ElementsY))\n",
    "               \n",
    "        ''' Calculate the Von Mises Stress'''\n",
    "        VonMises_element=np.sqrt((stressx_element*stressx_element)-(stressx_element*stressy_element)+(stressy_element*stressy_element)+(3*stressxy_element*stressxy_element))\n",
    "        VonMises_node=np.sqrt((stressx_node*stressx_node)-(stressx_node*stressy_node)+(stressy_node*stressy_node)+(3*stressxy_node*stressxy_node))\n",
    "\n",
    "        VonMises_node_nn=np.reshape(np.flip(VonMises_node,0),(((ElementsX+1)*(ElementsY+1),1)))\n",
    "        VonMises_nn=np.reshape(VonMises_element,((ElementsX*ElementsY),1))\n",
    "\n",
    "        VonMises_node_nn=max(VonMises_node_nn)/VonMises_node_nn\n",
    "        VonMises_node_nn[VonMises_node_nn>1e4]=0\n",
    "        VonMises_node_nn=VonMises_node_nn/max(VonMises_node_nn)\n",
    "        VonMises_nn=max(VonMises_nn)/VonMises_nn\n",
    "        VonMises_nn[VonMises_nn>1e3]=0\n",
    "        VonMises_nn=VonMises_nn/max(VonMises_nn)\n",
    "\n",
    "        \n",
    "    \n",
    "    if Stress is False:\n",
    "        VonMises_nn=[]\n",
    "\n",
    "    return(MaxDisplacements,StrainEnergy,VonMises_element,VonMises_nn,VonMises_node_nn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b3822",
   "metadata": {},
   "source": [
    "# OPTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa7f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Aug 16 10:17:32 2021\n",
    "\n",
    "@author: nbrow\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import argparse \n",
    "def parse_opts(args_in = None):\n",
    "  \n",
    "    parser=argparse.ArgumentParser()\n",
    "    ''' Parameters invovled with generic environment building'''\n",
    "    parser.add_argument('--Main_EX',\n",
    "                        default=24,\n",
    "                        type=int,\n",
    "                        help='Number of X Elements for Larger Environment')\n",
    "    \n",
    "    parser.add_argument('--Main_EY',\n",
    "                        default=24,\n",
    "                        type=int,\n",
    "                        help='Number of Y Elements for Larger Environment')\n",
    "    parser.add_argument('--PR2_EX',\n",
    "                    default=12,\n",
    "                    type=int,\n",
    "                    help='Number of X Elements for Second Environment used in Case of Progressive Refinement')\n",
    "    parser.add_argument('--PR2_EY',\n",
    "                    default=12,\n",
    "                    type=int,\n",
    "                    help='Number of Y Elements for Second Environment used in Case of Progressive Refinement')\n",
    "    parser.add_argument('--PR_EX',\n",
    "                    default=6,\n",
    "                    type=int,\n",
    "                    help='Number of X Elements for Smaller Environment used in Case of Progressive Refinement')\n",
    "    \n",
    "    parser.add_argument('--PR_EY',\n",
    "                    default=6,\n",
    "                    type=int,\n",
    "                    help='Number of Y Elements for Smaller Environment used in Case of Progressive Refinement')\n",
    "    \n",
    "    parser.add_argument('--Lx',\n",
    "                default=1,\n",
    "                type=int,\n",
    "                help='Length of the Structure in the X Direction')\n",
    "    \n",
    "    parser.add_argument('--Ly',\n",
    "                default=1,\n",
    "                type=int,\n",
    "                help='Length of the Structure in the Y Direction')\n",
    "    \n",
    "    ''' Parameters Invovled with the TopOpt environment'''\n",
    "    parser.add_argument('--Eta',\n",
    "                    default=2,\n",
    "                    type=int,\n",
    "                    help='Used for dynamic adjusting reward function. Larger eta means lest prevelance'\n",
    "                        'given towards changes between current and previous reward. Recommend using [2,4]')\n",
    "    parser.add_argument('--a',\n",
    "                    default=5,\n",
    "                    type=int,\n",
    "                    help='X Coefficient of the Quadratic Reward Sufarce')\n",
    "    \n",
    "    parser.add_argument('--b',\n",
    "                    default=5,\n",
    "                    type=int,\n",
    "                    help='Y Coefficient of the Quadratic Reward Sufarce')\n",
    "    ''' Parameters Involved with the RL Architecture'''\n",
    "    parser.add_argument('--replace',\n",
    "                    default=100,\n",
    "                    type=int,\n",
    "                    help='Number of iterations between switching the weights from the active network to the target network')\n",
    "       \n",
    "    parser.add_argument('--epsilon_dec',\n",
    "                    default=3.5e-4,\n",
    "                    type=float,\n",
    "                    help='Iterative decay amount of the epsilon value used for exploration/explotation')\n",
    "    parser.add_argument('--eps_end',\n",
    "                    default=0.01,\n",
    "                    type=float,\n",
    "                    help='Smallest Allowable Epsilon value to be used for exploration/explotation')\n",
    "    \n",
    "    parser.add_argument('--mem_size',\n",
    "                    default=30000,\n",
    "                    type=int,\n",
    "                    help='Size of the Replay Buffer')\n",
    "    parser.add_argument('--n_games',\n",
    "                    default=50_000,\n",
    "                    type=int,\n",
    "                    help='Maximum Number of Training Episodes Conducted')\n",
    "    \n",
    "    parser.add_argument('--batch_size',\n",
    "                    default=128,\n",
    "                    type=int,\n",
    "                    help='Batch Size that will be taken from the Replay Buffer per training episode')\n",
    "    \n",
    "    parser.add_argument('--lr',\n",
    "                    default=5e-3,\n",
    "                    type=float,\n",
    "                    help='Starting Learning Rate for the Network')\n",
    "    \n",
    "    parser.add_argument('--gamma',\n",
    "                    default=0.1,\n",
    "                    type=float,\n",
    "                    help='Discount Factor for Future Rewards ')\n",
    "    parser.add_argument('--Vol_Frac_1',\n",
    "                    default=0.7,\n",
    "                    type=float,\n",
    "                    help='Volume Fraction during first progressive refinement')\n",
    "    \n",
    "    parser.add_argument('--Vol_Frac_2',\n",
    "                    default=0.5,\n",
    "                    type=float,\n",
    "                    help='Final Volume Fraction ')\n",
    "    \n",
    "    parser.add_argument('--Vol_Frac_3',\n",
    "                    default=0.25,\n",
    "                    type=float,\n",
    "                    help='Final Volume Fraction ')\n",
    "\n",
    "    parser.add_argument('--SC',\n",
    "                    default=10,\n",
    "                    type=float,\n",
    "                    help='Stress constraint, between 0 and 2 ')\n",
    "    \n",
    "    parser.add_argument('--P_Norm',\n",
    "                    default=10,\n",
    "                    type=int,\n",
    "                    help='Smoothing Parameter for P-Norm Global Stress calculation')\n",
    "    parser.add_argument('--filename_save',\n",
    "                       default='DDQN_TopOpt_Generalized_CNN_4L_',\n",
    "                       type=str,\n",
    "                       help='When training, what name would you like your weights, and figure saved as')\n",
    "    parser.add_argument('--filename_load',\n",
    "                       default='DDQN_TopOpt_Generalized_CNN_4L_6by6',\n",
    "                       type=str,\n",
    "                       help='When testing, what name is your NN weights saved under')\n",
    "    parser.add_argument('--Progressive_Refinement',\n",
    "                       default=True,\n",
    "                       type=bool)\n",
    "    parser.add_argument('--LC',\n",
    "                       default=False,\n",
    "                       type=bool,\n",
    "                       help=\"type in loading conditions manually\")\n",
    "    parser.add_argument('--Load_Checkpoints',\n",
    "                       default=True,\n",
    "                       type=bool,\n",
    "                       help=\"Load Checkouts. \")\n",
    "    \n",
    "    parser.add_argument('--VF_S',\n",
    "                       default=0,\n",
    "                       type=int,\n",
    "                       help=\"Use vol fraction constraint [0] or stress constraint [1]\")\n",
    "    \n",
    "    parser.add_argument('--Min_Dist',\n",
    "                        default=0,\n",
    "                        type=int,\n",
    "                        help=\n",
    "                        \"The 0 value serves as a place holder to represent the minimum distance between the bounded\" \n",
    "                        \"and loaded elements in a given load case.\")\n",
    "    parser.add_argument('--Time_Trial',\n",
    "                       default=True,\n",
    "                       type=bool,\n",
    "                       help=\"Perform Time Trial\")\n",
    "    \n",
    "    parser.add_argument('--configfile',\n",
    "                       default='config.json',\n",
    "                       type=str,\n",
    "                       help=\"name of config file. \")\n",
    "    \n",
    "    parser.add_argument('--From_App',\n",
    "                       default=True,\n",
    "                       type=bool,\n",
    "                       help=\"True if being called by an external app. Not sure this is needed. \")\n",
    "\n",
    "    parser.add_argument('--base_folder',\n",
    "                       default=r\".\",\n",
    "                       type=str,\n",
    "                       help=\"Folder where to find saved files. Helpful if not running the app from the main folder.  \")\n",
    " \n",
    "\n",
    "    if args_in:\n",
    "        # print(f\"Using args {args_in}\")\n",
    "        # all_defaults = {}\n",
    "        # for key in vars(args):\n",
    "        #     all_defaults[key] = parser.get_default(key)\n",
    "        args = parser.parse_args(\"\")\n",
    "    else: args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4f272",
   "metadata": {},
   "source": [
    "# NODE_ELEMENT_EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 12 11:42:39 2021\n",
    "\n",
    "@author: nbrow\n",
    "\"\"\"\n",
    "# from Top_Opt_RL.DQN .FEA_SOLVER_GENERAL import rectangularmesh\n",
    "import numpy as np\n",
    "def LC_Nodes(Load_Element,Load_Type,Load_Direction,Lx,Ly,Elements_X,Elements_Y,Counting,Node_Location):\n",
    "    '''Given the loaded element and loading direction, \n",
    "    produce the nodes that should be loaded for the FEA. If the user is testing\n",
    "     and selects an element not on the exterior edges of the shape\n",
    "     they will be prompted to select the top/right/bottom/left nodes \n",
    "     of the selected element '''\n",
    "    Go_List,Elem_List,Bottom_List,Top_List,Left_List,Right_List=Element_Lists(Elements_X,Elements_Y)\n",
    "    Load_Nodes=rectangularmesh(Lx,Ly,Elements_X,Elements_Y)[1][Load_Element,:]\n",
    "    if Load_Element in Bottom_List:\n",
    "        Loaded_Node=Load_Nodes[0]\n",
    "        Loaded_Node2=Load_Nodes[1]\n",
    "    if Load_Element in Top_List:\n",
    "        Loaded_Node=Load_Nodes[2]\n",
    "        Loaded_Node2=Load_Nodes[3]\n",
    "    if Load_Element in Right_List:\n",
    "        Loaded_Node=Load_Nodes[1]\n",
    "        Loaded_Node2=Load_Nodes[2]\n",
    "    if Load_Element in Left_List:\n",
    "        Loaded_Node=Load_Nodes[0]\n",
    "        Loaded_Node2=Load_Nodes[3]\n",
    "    if Load_Element in Top_List and Load_Element in Right_List:\n",
    "        if Load_Type==1:\n",
    "            Loaded_Node=Load_Nodes[1]\n",
    "            Loaded_Node2=Load_Nodes[2]\n",
    "        else:\n",
    "            Loaded_Node=Load_Nodes[2]\n",
    "            Loaded_Node2=Load_Nodes[3]\n",
    "    if Load_Element in Top_List and Load_Element in Left_List:\n",
    "        if Load_Type==1:\n",
    "            Loaded_Node=Load_Nodes[0]\n",
    "            Loaded_Node2=Load_Nodes[3]\n",
    "        else:\n",
    "            Loaded_Node=Load_Nodes[2]\n",
    "            Loaded_Node2=Load_Nodes[3]\n",
    "    if Load_Element in Bottom_List and Load_Element in Right_List:\n",
    "        if Load_Type==1:\n",
    "            Loaded_Node=Load_Nodes[1]\n",
    "            Loaded_Node2=Load_Nodes[2]\n",
    "        else:\n",
    "            Loaded_Node=Load_Nodes[0]\n",
    "            Loaded_Node2=Load_Nodes[1]\n",
    "    if Load_Element in Bottom_List and Load_Element in Left_List:\n",
    "        if Load_Type==1:\n",
    "            Loaded_Node=Load_Nodes[0]\n",
    "            Loaded_Node2=Load_Nodes[3]\n",
    "        else:\n",
    "            Loaded_Node=Load_Nodes[0]\n",
    "            Loaded_Node2=Load_Nodes[1]\n",
    "    if Load_Element not in Bottom_List and Load_Element not in Top_List and Load_Element not in Right_List and Load_Element not in Left_List:\n",
    "        if Load_Type==0 and Load_Direction==-1:\n",
    "            Loaded_Node=Load_Nodes[0]\n",
    "            Loaded_Node2=Load_Nodes[1]\n",
    "        if Load_Type==1 and Load_Direction==1:\n",
    "            Loaded_Node=Load_Nodes[1]\n",
    "            Loaded_Node2=Load_Nodes[2]\n",
    "        if Load_Type==0 and Load_Direction==1:\n",
    "            Loaded_Node=Load_Nodes[2]\n",
    "            Loaded_Node2=Load_Nodes[3]\n",
    "        if Load_Type==1 and Load_Direction==-1:\n",
    "            Loaded_Node=Load_Nodes[3]\n",
    "            Loaded_Node2=Load_Nodes[0]\n",
    "    Loaded_Node=int(Loaded_Node)\n",
    "    Loaded_Node2=int(Loaded_Node2)   \n",
    "\n",
    "    return Loaded_Node, Loaded_Node2\n",
    "\n",
    "def BC_Nodes(Load_Element,Lx,Ly,Elements_X,Elements_Y):\n",
    "\n",
    "    ''''Given the Boundary Condition Element,produce the \n",
    "    corresponding nodes depending on where it's located'''\n",
    "\n",
    "    _,_,Bottom_List,Top_List,Left_List,Right_List=Element_Lists(Elements_X,Elements_Y)\n",
    "    Load_Nodes=rectangularmesh(Lx,Ly,Elements_X,Elements_Y)[1][Load_Element,:]\n",
    "    if Load_Element in Bottom_List:\n",
    "     \n",
    "        Loaded_Node=Load_Nodes[0]\n",
    "        Loaded_Node2=Load_Nodes[1]\n",
    "    if Load_Element in Top_List:\n",
    "  \n",
    "        Loaded_Node=Load_Nodes[2]\n",
    "        Loaded_Node2=Load_Nodes[3]\n",
    "    if Load_Element in Right_List:\n",
    "      \n",
    "        Loaded_Node=Load_Nodes[1]\n",
    "        Loaded_Node2=Load_Nodes[2]\n",
    "    if Load_Element in Left_List:\n",
    "       \n",
    "        Loaded_Node=Load_Nodes[0]\n",
    "        Loaded_Node2=Load_Nodes[3]\n",
    "    if Load_Element in Top_List and Load_Element in Right_List:\n",
    "        Loaded_Node=Load_Nodes[2]\n",
    "        Loaded_Node2=Load_Nodes[2]\n",
    "    if Load_Element in Top_List and Load_Element in Left_List:\n",
    "        Loaded_Node=Load_Nodes[3]\n",
    "        Loaded_Node2=Load_Nodes[3]\n",
    "    if Load_Element in Bottom_List and Load_Element in Right_List:\n",
    "        Loaded_Node=Load_Nodes[1]\n",
    "        Loaded_Node2=Load_Nodes[1]\n",
    "\n",
    "    if Load_Element in Bottom_List and Load_Element in Left_List:\n",
    "        Loaded_Node=Load_Nodes[0]\n",
    "        Loaded_Node2=Load_Nodes[0]\n",
    "    if Load_Element not in Bottom_List and Load_Element not in Top_List and Load_Element not in Right_List and Load_Element not in Left_List:\n",
    "        Loaded_Node=Load_Nodes[0]\n",
    "        Loaded_Node2=Load_Nodes[1]\n",
    "\n",
    "    Loaded_Node=int(Loaded_Node)\n",
    "    Loaded_Node2=int(Loaded_Node2)   \n",
    "    return Loaded_Node, Loaded_Node2\n",
    "\n",
    "def Element_Lists(Elements_X,Elements_Y):\n",
    "    '''Simple function that produces a list of all the elements in the matrix '''\n",
    "    Go_List=[]\n",
    "    Elem_List=[]\n",
    "    Go_List=np.append(Go_List,range(0,Elements_X+1))\n",
    "    Elem_List=np.append(Elem_List,range(0,Elements_X))\n",
    "\n",
    "    for num in range(0,Elements_Y-1):\n",
    "        Go_List=np.append(Go_List,(Elements_X+1)*(num+1))\n",
    "        Go_List=np.append(Go_List,(Elements_X+1)*(num+2)-1)\n",
    "    Go_List=np.append(Go_List,range((Elements_X*(Elements_Y+1)),(Elements_X*(Elements_Y+2)+1)))\n",
    "    for num in range(0,Elements_Y-2):\n",
    "        Elem_List=np.append(Elem_List,(Elements_X*(num+1)))\n",
    "        Elem_List=np.append(Elem_List,(Elements_X*(num+2)-1))\n",
    "    Elem_List=np.append(Elem_List,range(Elements_X*(Elements_Y-1),(Elements_X*(Elements_Y))))\n",
    "    Bottom_List=np.arange(0, Elements_X,1).tolist()\n",
    "    Top_List=np.arange(Elements_X*(Elements_Y-1),Elements_X*Elements_Y, 1).tolist()\n",
    "    Left_List=np.arange(0, Elements_X*(Elements_Y),Elements_X).tolist()\n",
    "    Right_List=np.arange(Elements_X-1,Elements_X*Elements_Y+1,Elements_X).tolist()\n",
    "\n",
    "    return Go_List, Elem_List, Bottom_List, Top_List,Left_List,Right_List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e625d424",
   "metadata": {},
   "source": [
    "# MATRIX_TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6895f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 12 15:34:50 2021\n",
    "\n",
    "@author: nbrow\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.signal import convolve2d\n",
    "# from Top_Opt_RL.DQN. Node_Element_Extraction import BC_Nodes,LC_Nodes\n",
    "def action_flip(action,Elements_X,Elements_Y):\n",
    "    \n",
    "    '''Given an element that is being loaded, produce the \n",
    "    element horizontally, vertically, and diagonally mirrored to it'''\n",
    "    Action_Mat=np.zeros((1,Elements_X*Elements_Y))\n",
    "    Action_Mat[0][action]=1\n",
    "    Action_Mat=np.reshape(Action_Mat,(Elements_X,Elements_Y))\n",
    "    AM_v=np.reshape(np.flip(Action_Mat,axis=0),(1,Elements_X*Elements_Y))\n",
    "    AM_h=np.reshape(np.flip(Action_Mat,axis=1),(1,Elements_X*Elements_Y))\n",
    "    AM_vh=np.reshape(np.flip(np.reshape(AM_v,(Elements_X,Elements_Y)),axis=1),(1,Elements_X*Elements_Y))\n",
    "    action_v=np.where(AM_v[0]==1)[0][0]\n",
    "    action_h=np.where(AM_h[0]==1)[0][0]\n",
    "    action_vh=np.where(AM_vh[0]==1)[0][0]\n",
    "    return action_v,action_h,action_vh \n",
    "\n",
    "def obs_flip(observation,Elements_X,Elements_Y):\n",
    "    '''Given an observation, produce the observations \n",
    "    that are horizontally, vertically, and diagonally mirrored'''\n",
    "    \n",
    "    \n",
    "    observation_v=np.zeros((Elements_X,Elements_Y,3))\n",
    "    observation_h=np.zeros((Elements_X,Elements_Y,3))\n",
    "    observation_vh=np.zeros((Elements_X,Elements_Y,3))\n",
    "    for Flip in range(0,3):\n",
    "        observation_v[:,:,Flip]=np.flip(observation[:,:,Flip],axis=0)\n",
    "        observation_h[:,:,Flip]=np.flip(observation[:,:,Flip],axis=1)\n",
    "    for Flip in range(0,3):\n",
    "        observation_vh[:,:,Flip]=np.flip(observation_v[:,:,Flip],axis=1)\n",
    "        \n",
    "    return observation_v,observation_h,observation_vh\n",
    "\n",
    "def Mesh_Triming(env,Elements_X,Elements_Y):\n",
    "    '''This function can be used to eleminate elements that are only \n",
    "    singularly connected to the rest of the matrix and do not provide \n",
    "    substantial support to the rest of the structure. It can be thought\n",
    "    of as a shaving algorithm to help catch single elements the RL agent mises \n",
    "    at the end'''\n",
    "    Final=False\n",
    "    Count_1=list(env.VoidCheck).count(0)\n",
    "    while not Final:\n",
    "        VC_Hold=np.zeros((Elements_X+2,Elements_Y+2))\n",
    "        VC_Hold[1:Elements_X+1,1:Elements_Y+1]=np.reshape(env.VoidCheck,(Elements_X,Elements_Y))\n",
    "        c = convolve2d(VC_Hold, np.array([[0,1,0],[1,0,1],[0,1,0]]), mode='valid')\n",
    "        VV=VC_Hold[1:Elements_X+1,1:Elements_Y+1]\n",
    "        VV_Loc=np.where(np.reshape(VV,(1,(Elements_X*Elements_Y)))==0)[1]\n",
    "        c=np.reshape(c,(1,Elements_X*Elements_Y))[0]\n",
    "        c[VV_Loc]=0\n",
    "        c_Loc=np.where(c==1)[0]\n",
    "        for i in range(0,len(env.BC)):\n",
    "            c_Loc=np.delete(c_Loc,np.where(c_Loc==env.BC[i]))\n",
    "        if len(c_Loc)>0:\n",
    "            Final=False\n",
    "        else:\n",
    "            Final=True\n",
    "\n",
    "        if len(c_Loc)>0:\n",
    "            try:\n",
    "                env.VoidCheck[c_Loc]=0 \n",
    "            except TypeError:\n",
    "                env.VoidCheck[c_Loc[0]]=0\n",
    "    Count_2=list(env.VoidCheck).count(0)\n",
    "    return Count_2-Count_1  \n",
    "\n",
    "def Condition_Transform(Lx,Ly,Old_EX,Old_EY,New_EX,New_EY,BC_Elements,LC_Elements,Load_Type,Load_Direction):\n",
    "    New_BC_Elements=[]\n",
    "    New_BC_Nodes=[]\n",
    "    New_LC_Elements=[]\n",
    "    New_LC_Nodes=[]\n",
    "    for BC in range(0,len(BC_Elements)):\n",
    "        BC1_E=BC_Elements[BC]\n",
    "        Row_BC1_E=math.floor(BC1_E/New_EY)\n",
    "        Col_BC1_E=math.floor(round(math.modf(BC1_E/New_EX)[0],2)*New_EX)\n",
    "\n",
    "        Old_X_Perc_BC1_E=Row_BC1_E/New_EY\n",
    "        Old_Y_Perc_BC1_E=Col_BC1_E/New_EX\n",
    "\n",
    "        New_Row_BC1_E=math.floor((Old_X_Perc_BC1_E*Old_EX)+0.001)\n",
    "        New_Col_BC1_E=math.floor((Old_Y_Perc_BC1_E*Old_EY)+0.001)\n",
    "        New_BC1_E=(New_Row_BC1_E*Old_EX)+New_Col_BC1_E\n",
    "        New_BC1,New_BC2=BC_Nodes(New_BC1_E,Lx,Ly,Old_EX,Old_EY)\n",
    "        New_BC_Elements=np.append(New_BC_Elements,New_BC1_E)\n",
    "        New_BC_Nodes=np.append(New_BC_Nodes,New_BC1)\n",
    "        New_BC_Nodes=np.append(New_BC_Nodes,New_BC2)\n",
    "    \n",
    "    for LC_ in range(0,len(LC_Elements)):\n",
    "        LC=LC_Elements[LC_]\n",
    "        Row_LC=math.floor(LC/New_EY)\n",
    "        Col_LC=math.floor(round(math.modf(LC/New_EX)[0],2)*New_EX)\n",
    "        Old_X_Perc=Row_LC/New_EY\n",
    "        Old_Y_Perc=Col_LC/New_EX\n",
    "        New_Row_LC=math.floor((Old_X_Perc*Old_EX)+0.001)\n",
    "        New_Col_LC=math.floor((Old_Y_Perc*Old_EY)+0.001)\n",
    "        New_LC_E=(New_Row_LC*Old_EX)+New_Col_LC\n",
    "        New_LC1,New_LC2=LC_Nodes(New_LC_E,Load_Type[LC_],Load_Direction[LC_],Lx,Ly,Old_EX,Old_EY,LC_,Node_Location=False)\n",
    "        New_LC_Elements=np.append(New_LC_Elements,New_LC_E)\n",
    "        New_LC_Nodes=np.append(New_LC_Nodes,New_LC1)\n",
    "        New_LC_Nodes=np.append(New_LC_Nodes,New_LC2)\n",
    "    \n",
    "    return New_BC_Nodes,New_BC_Elements,New_LC_Elements,New_LC_Nodes,Load_Direction\n",
    "\n",
    "def Mesh_Transform(Old_EX,Old_EY,New_EX,New_EY,Config):\n",
    "\n",
    "    Config=np.reshape(Config,(Old_EX,Old_EY))\n",
    "    Old_X_Perc=100/Old_EX\n",
    "    Old_Y_Perc=100/Old_EY\n",
    "    New_X_Perc=100/New_EX\n",
    "    New_Y_Perc=100/New_EY\n",
    "    \n",
    "    New_Config=np.zeros((New_EY,New_EX))\n",
    "    for i in range(Old_EX):\n",
    "        for j in range(Old_EY):\n",
    "            if Config[i,j]==1:\n",
    "                Old_X_Min=j*Old_X_Perc\n",
    "                Old_X_Max=(j+1)*Old_X_Perc\n",
    "                Old_Y_Min=i*Old_Y_Perc\n",
    "                Old_Y_Max=(i+1)*Old_Y_Perc\n",
    "                New_X_Block_Max=math.ceil(Old_X_Max/New_X_Perc)\n",
    "                if New_X_Block_Max!=0:\n",
    "                    New_X_Block_Max-=1\n",
    "                New_X_Block_Min=math.floor(Old_X_Min/New_X_Perc)\n",
    "                #if New_X_Block_Min!=0:\n",
    "                #    New_X_Block_Min-=1\n",
    "                New_Y_Block_Max=math.ceil(Old_Y_Max/New_Y_Perc)\n",
    "                if New_Y_Block_Max!=0:\n",
    "                    New_Y_Block_Max-=1\n",
    "                New_Y_Block_Min=math.floor(Old_Y_Min/New_Y_Perc)\n",
    "                #if New_Y_Block_Min!=0:\n",
    "                #    New_Y_Block_Min-=1\n",
    "                New_Config[New_Y_Block_Min:New_Y_Block_Max+1,New_X_Block_Min:New_X_Block_Max+1:1]=1\n",
    "    New_Config=np.reshape(New_Config,(1,New_EX*New_EY))\n",
    "    \n",
    "    return list(New_Config[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a34a50",
   "metadata": {},
   "source": [
    "# TOPOPT_ENV_FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc670673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 12 12:00:02 2021\n",
    "\n",
    "@author: nbrow\n",
    "\"\"\"\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete\n",
    "import numpy as np\n",
    "import itertools\n",
    "# from Top_Opt_RL.DQN.Node_Element_Extraction import BC_Nodes,LC_Nodes,Element_Lists\n",
    "# from Top_Opt_RL.DQN.FEA_SOLVER_GENERAL import FEASolve, isolate_largest_group_original, rectangularmesh\n",
    "import math\n",
    "import copy\n",
    "# from Top_Opt_RL.DQN. Matrix_Transforms import Condition_Transform\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    " \n",
    "class TopOpt_Gen(Env):\n",
    "    def __init__(self,Elements_X,Elements_Y,Vol_Frac,SC,opts):\n",
    "        #Actons we can take... remove any of the blocks\n",
    "        self.EX=Elements_X\n",
    "        self.p=opts.P_Norm\n",
    "        self.RS=Reward_Surface(opts)[0]\n",
    "        self.RV=Reward_Surface(opts)[1]\n",
    "        self.SC=SC\n",
    "        self.Lx=opts.Lx\n",
    "        self.EY=Elements_Y\n",
    "        self.Ly=opts.Ly\n",
    "        self.action_space=Discrete(self.EX*self.EY)\n",
    "        self.eta=opts.Eta\n",
    "        self.Vol_Frac=Vol_Frac\n",
    "    def step(self,action,observation,Last_Reward,load_checkpoint,env,PR,FEA_Skip):\n",
    "        #Apply Action\n",
    "        self.Counter+=1    \n",
    "        # evaluate it on grid\n",
    "\n",
    "        rs_place=self.VoidCheck[int(action)]\n",
    "        self.VoidCheck[int(action)]=0\n",
    "        ElementMat=np.reshape(self.VoidCheck,(self.EX,self.EY))\n",
    "        SingleCheck=isolate_largest_group_original(ElementMat)\n",
    "        It=list(self.VoidCheck).count(0)\n",
    "        if rs_place==1 and action not in self.BC and SingleCheck[1]==True:\n",
    "            done=False\n",
    "            if It>=math.ceil((self.EX*self.EY)*(1-self.Vol_Frac)) and load_checkpoint or It>=math.ceil((self.EX*self.EY)*(1-self.Vol_Frac)) and PR:\n",
    "                done=True\n",
    "            if self.Counter==1 or (self.Counter/FEA_Skip)==int(self.Counter/FEA_Skip):\n",
    "                Run_Results=FEASolve(list(self.VoidCheck),self.Lx,self.Ly,self.EX,self.EY,self.LC_Nodes,self.Load_Directions,self.BC_Nodes,Stress=True)\n",
    "                self.Max_SE_Ep=np.max(Run_Results[1])\n",
    "                if (env.P_Norm/(sum(sum([number**self.p for number in np.reshape(Run_Results[2],(1,self.EX*self.EY))]))**(1/self.p)))<(1-float(self.SC)):\n",
    "\n",
    "                    done=True\n",
    "                    print('STRESS CONSTRAINT HIT!')\n",
    "            else:\n",
    "                self.Stress_state=np.reshape(self.Stress_state,(1,self.EX*self.EY))\n",
    "                self.Stress_state[0][action]=0\n",
    "                self.Stress_state=np.reshape(self.Stress_state,(self.EX,self.EY))\n",
    "            \n",
    "            if abs(self.Max_SE_Tot/self.Max_SE_Ep)>=1 or abs(It/(self.EX*self.EY))>=1 or self.Max_SE_Tot==0 or self.Max_SE_Ep==0:\n",
    "                reward=-1\n",
    "                done=True\n",
    "            else:\n",
    "                reward = self.RS[(int((self.Max_SE_Tot/self.Max_SE_Ep)*1000))-1,int((It/(self.EX*self.EY))*1000)-1]\n",
    "                if not load_checkpoint:\n",
    "                    reward2=self.RV[int(1-(np.reshape(self.Stress_state,(self.EX*self.EY,1))[action])*1000)-1]\n",
    "                    reward=np.mean([reward,reward2])\n",
    "            if self.Counter==1 or (self.Counter/FEA_Skip)==int(self.Counter/FEA_Skip):\n",
    "             \n",
    "                self.Stress_state=Run_Results[3]\n",
    "                self.Stress_state=np.reshape(self.Stress_state,(self.EX,self.EY))\n",
    "            self.state=np.zeros((self.EX,self.EY,3))\n",
    "            self.state[:,:,0]=self.Stress_state\n",
    "            self.state[:,:,1]=self.BC_state\n",
    "            self.state[:,:,2]=self.LC_state\n",
    "        else:\n",
    "            \"\"\"If the removed block has already been removed, leads to a non-singular\n",
    "            body or one of the Boundary condition blocks, the agent should be severely punished (-1)\"\"\"\n",
    "            Run_Results=FEASolve(list(self.VoidCheck),self.Lx,self.Ly,self.EX,self.EY,self.LC_Nodes,self.Load_Directions,self.BC_Nodes,Stress=True)\n",
    "            self.Max_SE_Ep=np.max(Run_Results[1])\n",
    "            self.Stress_state=Run_Results[3]\n",
    "            self.Stress_state=np.reshape(self.Stress_state,(self.EX,self.EY))\n",
    "            self.state=np.zeros((self.EX,self.EY,3))\n",
    "            self.state[:,:,0]=self.Stress_state\n",
    "            self.state[:,:,1]=self.BC_state\n",
    "            self.state[:,:,2]=self.LC_state\n",
    "            reward=-1\n",
    "            done=True\n",
    "            if rs_place==1:\n",
    "                self.VoidCheck[int(action)]=1\n",
    "            \n",
    "        reward+=1e-4\n",
    "        Last_Reward+=1e-4\n",
    "        rho=((reward)-(Last_Reward))/min([reward,Last_Reward])\n",
    "        if reward>Last_Reward:\n",
    "            llambda=1\n",
    "        else:\n",
    "            llambda=-1\n",
    "        x=rho+llambda\n",
    "        f_x=math.atan(x*(math.pi/2)*(1/self.eta))\n",
    "        reward=reward+(f_x-llambda)*abs(reward)\n",
    "        \n",
    "\n",
    "        return self.state, reward, done, It\n",
    "    \n",
    "    def render(self,mode='human'):\n",
    "        RenderMat=copy.deepcopy(self.VoidCheck)\n",
    "        for RM in range(0,len(self.BC_Elements)):\n",
    "            RenderMat[int(self.BC_Elements[RM])]=2\n",
    "            RenderMat[int(self.BC_Elements[RM])]=2\n",
    "        for RM in range(0,len(self.LC_Elements)):\n",
    "            RenderMat[int(self.LC_Elements[RM])]=4\n",
    "        RenderMat=np.reshape(RenderMat,(self.EX,self.EY))\n",
    "        print(np.flip(RenderMat,0))\n",
    "        print('')\n",
    "        return \n",
    "        \n",
    "    def reset(self):\n",
    "\n",
    "        self.Results=FEASolve(self.VoidCheck,self.Lx,self.Ly,self.EX,self.EY,self.LC_Nodes,self.Load_Directions,self.BC_Nodes,Stress=True)\n",
    "        self.Stress_state=self.Results[3]\n",
    "        self.P_Norm=sum(sum([number**self.p for number in np.reshape(self.Results[2],(1,self.EX*self.EY))]))**(1/self.p)        #self.Stress_state=list(np.array(self.Stress_state)\n",
    "        self.Stress_state=np.reshape(self.Stress_state,(self.EX,self.EY))\n",
    "        self.state=np.zeros((self.EX,self.EY,3))\n",
    "        self.state[:,:,0]=self.Stress_state\n",
    "        self.state[:,:,1]=self.BC_state\n",
    "        self.state[:,:,2]=self.LC_state\n",
    "        self.Counter=0\n",
    "\n",
    "        return self.state\n",
    "    def reset_conditions(self):\n",
    "        self.Max_SE_Tot=0\n",
    "        self.VoidCheck=np.ones((1,self.EX*self.EY))\n",
    "        self.VoidCheck=list(self.VoidCheck[0])\n",
    "        self.VoidCheck=np.array(self.VoidCheck)\n",
    "\n",
    "        while self.Max_SE_Tot<=0 or self.Max_SE_Tot>5000:        \n",
    "            self.BC_Elements=[]\n",
    "            self.BC_Nodes=[]\n",
    "            self.LC_Elements=[]\n",
    "            self.LC_Nodes=[]\n",
    "            self.BC=[]\n",
    "            self.Load_Types=[]\n",
    "            self.Load_Directions=[]\n",
    "            self.BC_Elements=np.append(self.BC_Elements,int(random.choice([i for i in Element_Lists(self.EX,self.EY)[1]])))\n",
    "            self.BC_Elements=np.append(self.BC_Elements,int(random.choice([i for i in Element_Lists(self.EX,self.EY)[1]])))\n",
    "            while self.BC_Elements[0]==self.BC_Elements[1]:\n",
    "                self.BC_Elements[1]=int(random.choice([i for i in Element_Lists(self.EX,self.EY)[1]]))\n",
    "            self.BC_Nodes=np.append(self.BC_Nodes,BC_Nodes(int(self.BC_Elements[0]),self.Lx,self.Ly,self.EX,self.EY)[0])\n",
    "            self.BC_Nodes=np.append(self.BC_Nodes,BC_Nodes(int(self.BC_Elements[0]),self.Lx,self.Ly,self.EX,self.EY)[1])\n",
    "            self.BC_Nodes=np.append(self.BC_Nodes,BC_Nodes(int(self.BC_Elements[1]),self.Lx,self.Ly,self.EX,self.EY)[0])\n",
    "            self.BC_Nodes=np.append(self.BC_Nodes,BC_Nodes(int(self.BC_Elements[1]),self.Lx,self.Ly,self.EX,self.EY)[1])\n",
    "\n",
    "      \n",
    "            self.LC_Elements=np.append(self.LC_Elements,int(random.choice([i for i in Element_Lists(self.EX,self.EY)[1]])))\n",
    "            while self.LC_Elements[0] in self.BC_Elements:\n",
    "                self.LC_Elements[0]=int(random.choice([i for i in Element_Lists(self.EX,self.EY)[1]]))\n",
    "            \n",
    "            self.BC_set=np.append(self.BC_Elements,self.LC_Elements)\n",
    "            self.LC_state=list(np.zeros((1,self.EX*self.EY))[0])\n",
    "            for LCS in range(0,len(self.LC_Elements)):\n",
    "                self.LC_state[int(self.LC_Elements[LCS])]=1\n",
    "            self.LC_state=np.reshape(self.LC_state,(self.EX,self.EY))\n",
    "            self.Load_Types=np.append(self.Load_Types,random.choice([0,1]))\n",
    "            self.LC_Nodes=np.append(self.LC_Nodes,LC_Nodes(int(self.LC_Elements[0]),self.Load_Types,self.Load_Directions,self.Lx,self.Ly,self.EX,self.EY,LCS,Node_Location=False)[0])\n",
    "            self.LC_Nodes=np.append(self.LC_Nodes,LC_Nodes(int(self.LC_Elements[0]),self.Load_Types,self.Load_Directions,self.Lx,self.Ly,self.EX,self.EY,LCS,Node_Location=False)[1])\n",
    "            if self.Load_Types[0]==0: #Load will be applied vertically\n",
    "                self.LC_Nodes[0]+=((self.EX+1)*(self.EY+1))\n",
    "                self.LC_Nodes[1]+=((self.EX+1)*(self.EY+1))\n",
    "            self.Load_Directions=np.append(self.Load_Directions,random.choice([-1,1])) #1 for Compressive Load, -1 for tensile load\n",
    "            self.BC=np.append(self.BC,self.BC_Elements)\n",
    "            self.BC=np.append(self.BC,self.LC_Elements)\n",
    "            self.BC_state=list(np.zeros((1,self.EX*self.EY))[0])\n",
    "            for BCS in range(0,len(self.BC_Elements)):\n",
    "                self.BC_state[int(self.BC_Elements[BCS])]=1\n",
    "            self.BC_state=np.reshape(self.BC_state,(self.EX,self.EY))\n",
    "            self.Results=FEASolve(self.VoidCheck,self.Lx,self.Ly,self.EX,self.EY,self.LC_Nodes,self.Load_Directions,self.BC_Nodes,Stress=True)\n",
    "            self.Max_SE_Tot=self.Results[1]\n",
    "            \n",
    "    def primer_cond(self,EX,EY):\n",
    "        self.BC=[]\n",
    "        self.BC=np.append(self.BC,self.BC_Elements)\n",
    "        self.BC=np.append(self.BC,self.LC_Elements)\n",
    "        self.BC_state=list(np.zeros((1,EX*EY))[0])\n",
    "        for BCS in range(0,len(self.BC_Elements)):\n",
    "            self.BC_state[int(self.BC_Elements[BCS])]=1\n",
    "            self.BC_state=np.reshape(self.BC_state,(EX,EY))\n",
    "            self.LC_state=list(np.zeros((1,EX*EY))[0])\n",
    "            for LCS in range(0,len(self.LC_Elements)):\n",
    "                self.LC_state[int(self.LC_Elements[LCS])]=1\n",
    "                self.LC_state=np.reshape(self.LC_state,(EX,EY))\n",
    "                self.Results=FEASolve(self.VoidCheck,self.Lx,self.Ly,self.EX,self.EY,self.LC_Nodes,self.Load_Directions,self.BC_Nodes,Stress=True)\n",
    "                self.Max_SE_Tot=np.max(self.Results[1])\n",
    "\n",
    "def Prog_Refine_Act(agent_primer,env,env_primer,load_checkpoint,Testing,opts,Small_EX,Small_EY,Time_Trial,From_App,FEA_Skip):\n",
    "    '''This function will deliver the optimal topology of the smaller sized environment.\n",
    "    This final topology will then be transformed into the equivalent topology at the \n",
    "    larger selected size. This larger topology will then be based back to the main function\n",
    "    and the topology removal process will continue.'''\n",
    "    Stable=False\n",
    "    while not Stable:\n",
    "        env_primer.BC_Nodes,env_primer.BC_Elements,env_primer.LC_Elements,env_primer.LC_Nodes,env_primer.Load_Directions=Condition_Transform(opts.Lx,opts.Ly,Small_EX,Small_EY,opts.Main_EX,opts.Main_EY,env.BC_Elements,env.LC_Elements,env.Load_Types,env.Load_Directions)\n",
    "        \n",
    "        LN_Hold=env_primer.LC_Nodes\n",
    "        LT_Count=0\n",
    "        for Counting in range(0,len(env_primer.LC_Nodes)):\n",
    "            if Counting/2==int(Counting/2) and Counting/2!=0:\n",
    "                LT_Count+=1\n",
    "            if env.Load_Types[LT_Count]==0:\n",
    "                env_primer.LC_Nodes[Counting]+=((Small_EX+1)*(Small_EY+1))\n",
    "        env_primer.primer_cond(Small_EX,Small_EY)\n",
    "        for Check in range(0,len(LN_Hold)):\n",
    "            if LN_Hold[Check] in env_primer.BC_Nodes:\n",
    "                if load_checkpoint:\n",
    "                    print('-------------------------------')\n",
    "                    print('Illegal Combination of BC and LC')\n",
    "                    print('-------------------------------')\n",
    "                    sys.exit()\n",
    "                env.reset_conditions()\n",
    "            else:\n",
    "                Stable=True\n",
    "    primer_done=False\n",
    "    observation_primer=env_primer.reset()\n",
    "    Last_Reward=0\n",
    "    while not primer_done:\n",
    "        Testing=True\n",
    "        action = agent_primer.choose_action(observation_primer,load_checkpoint,Testing)\n",
    "        observation_primer_, reward, primer_done, It = env_primer.step(action,observation_primer,Last_Reward,load_checkpoint,env,FEA_Skip=FEA_Skip,PR=True)\n",
    "        observation_primer = observation_primer_\n",
    "        Last_Reward=reward\n",
    "        if load_checkpoint and not Time_Trial:\n",
    "            env_primer.render()\n",
    "    Last_Reward=0\n",
    "    if Testing and not From_App:\n",
    "        env_primer.render()\n",
    "def Min_Dist_Calc(UC_,opts):\n",
    "    \n",
    "    BC=[int(x)-1 for x in UC_['bcs']]\n",
    "    Right=[int(x)-1 for x in UC_['rights']]\n",
    "    Left=[int(x)-1 for x in UC_['lefts']]\n",
    "    Up=[int(x)-1 for x in UC_['ups']]\n",
    "    Down=[int(x)-1 for x in UC_['downs']]\n",
    "    Elements=[]\n",
    "    Elements=np.append(Elements,Right)\n",
    "    Elements=np.append(Elements,Left)\n",
    "    Elements=np.append(Elements,Up)\n",
    "    Elements=np.append(Elements,Down)\n",
    "    Elements=np.append(Elements,BC)\n",
    "\n",
    "    Len_Mat=[]\n",
    "    for i in range(0,len(Elements)):\n",
    "        for j in range(i+1,len(Elements)):\n",
    "            Row_E1=math.floor(Elements[i]/opts.Main_EX)\n",
    "            Col_E1=math.ceil(math.modf(Elements[i]/opts.Main_EX)[0]*opts.Main_EX)\n",
    "            Row_E2=math.floor(Elements[j]/opts.Main_EX)\n",
    "            Col_E2=math.ceil(math.modf(Elements[j]/opts.Main_EX)[0]*opts.Main_EX)\n",
    "            E2_E1=abs(Row_E2-Row_E1)+abs(Col_E2-Col_E1)\n",
    "            Len_Mat=np.append(Len_Mat,E2_E1)\n",
    "    Len_Mat=list(Len_Mat)\n",
    "    while len(Len_Mat)>len(Elements):\n",
    "        Len_Mat.remove(max(Len_Mat))\n",
    "    return sum(Len_Mat)\n",
    "def App_Inputs(env,env_primer,env_primer2,opts,User_Conditions):\n",
    "    '''To improve the adaptability of this method, a web-app has been developed\n",
    "    using Heroku The web-app will provide an interactive environment for the user\n",
    "    to select the boundary and loading conditions. The BCs and LCs will be imported as \n",
    "    a .json file and distributed accordingly similar to the User_Input function'''\n",
    "    env.BC_Elements=[]\n",
    "    env.LC_Elements=[]\n",
    "    env.BC_Nodes=[]\n",
    "    env.LC_Nodes=[]\n",
    "    env.Load_Types=[]\n",
    "    env.Load_Directions=[]\n",
    "\n",
    "    BC=[int(x)-1 for x in User_Conditions['bcs']]\n",
    "    Right=[int(x)-1 for x in User_Conditions['rights']]\n",
    "    Left=[int(x)-1 for x in User_Conditions['lefts']]\n",
    "    Up=[int(x)-1 for x in User_Conditions['ups']]\n",
    "    Down=[int(x)-1 for x in User_Conditions['downs']]\n",
    "    env.BC_Elements=np.append(env.BC_Elements,BC)\n",
    "    env.Vol_Frac=User_Conditions['volfraction']\n",
    "    Min_Dist=Min_Dist_Calc(User_Conditions,opts)\n",
    "    env_primer.Vol_Frac=env.Vol_Frac+3*(Min_Dist/(opts.Main_EX*opts.Main_EY))\n",
    "    if env_primer.Vol_Frac>0.7:\n",
    "        env_primer.Vol_Frac=0.7\n",
    "    env_primer2.Vol_Frac=env.Vol_Frac+2*(Min_Dist/(opts.Main_EX*opts.Main_EY))\n",
    "    if env_primer2.Vol_Frac>0.5:\n",
    "        env_primer2.Vol_Frac=0.5\n",
    "    env.LC_Elements=np.append(env.LC_Elements,Right).astype('int')\n",
    "    env.Load_Types=np.append(env.Load_Types,[1]*len(Right)).astype('int')\n",
    "    env.Load_Directions=np.append(env.Load_Directions,[-1]*len(Right)).astype('int')\n",
    "    \n",
    "    env.LC_Elements=np.append(env.LC_Elements,Left).astype('int')\n",
    "    env.Load_Types=np.append(env.Load_Types,[1]*len(Left)).astype('int')\n",
    "    env.Load_Directions=np.append(env.Load_Directions,[-1]*len(Left)).astype('int')\n",
    "    \n",
    "    env.LC_Elements=np.append(env.LC_Elements,Up).astype('int')\n",
    "    env.Load_Types=np.append(env.Load_Types,[0]*len(Up)).astype('int')\n",
    "    env.Load_Directions=np.append(env.Load_Directions,[-1]*len(Up)).astype('int')\n",
    "    \n",
    "    env.LC_Elements=np.append(env.LC_Elements,Down).astype('int')\n",
    "    env.Load_Types=np.append(env.Load_Types,[0]*len(Down)).astype('int')\n",
    "    env.Load_Directions=np.append(env.Load_Directions,[-1]*len(Down)).astype('int')\n",
    "    for Counting in range(0,len(env.LC_Elements)):\n",
    "        if env.Load_Types[Counting]==0:\n",
    "            LC_New_Nodes=LC_Nodes(int(env.LC_Elements[Counting]),env.Load_Types[Counting],env.Load_Directions[Counting],env.Lx,env.Ly,env.EX,env.EY,Counting,Node_Location=True)\n",
    "            env.LC_Nodes=np.append(env.LC_Nodes,LC_New_Nodes[0]+(opts.Main_EX+1)*(opts.Main_EY+1))\n",
    "            env.LC_Nodes=np.append(env.LC_Nodes,LC_New_Nodes[1]+(opts.Main_EX+1)*(opts.Main_EY+1))\n",
    "        else:\n",
    "            LC_New_Nodes=LC_Nodes(int(env.LC_Elements[Counting]),env.Load_Types[Counting],env.Load_Directions[Counting],env.Lx,env.Ly,env.EX,env.EY,Counting,Node_Location=True)\n",
    "            env.LC_Nodes=np.append(env.LC_Nodes,LC_New_Nodes[0])\n",
    "            env.LC_Nodes=np.append(env.LC_Nodes,LC_New_Nodes[1])\n",
    "    for Counting in range(0,len(env.BC_Elements)):\n",
    "        env.BC_Nodes=np.append(env.BC_Nodes,BC_Nodes(int(env.BC_Elements[Counting]),env.Lx,env.Ly,env.EX,env.EY)[0])\n",
    "        env.BC_Nodes=np.append(env.BC_Nodes,BC_Nodes(int(env.BC_Elements[Counting]),env.Lx,env.Ly,env.EX,env.EY)[1])\n",
    "\n",
    "    env.LC_state=list(np.zeros((1,(opts.Main_EX)*(opts.Main_EY)))[0])\n",
    "    for LCS in range(0,len(env.LC_Elements)):\n",
    "                env.LC_state[int(env.LC_Elements[LCS])]=1\n",
    "    env.LC_state=np.reshape(env.LC_state,(opts.Main_EX,opts.Main_EY))\n",
    "    env.BC=[]\n",
    "    env.BC=np.append(env.BC,env.BC_Elements)\n",
    "    env.BC=np.append(env.BC,env.LC_Elements)\n",
    "    env.BC_state=list(np.zeros((1,(opts.Main_EX)*(opts.Main_EY)))[0])\n",
    "    for BCS in range(0,len(env.BC_Elements)):\n",
    "        env.BC_state[int(env.BC_Elements[BCS])]=1\n",
    "    env.BC_state=np.reshape(env.BC_state,(opts.Main_EX,opts.Main_EY))\n",
    "    env.Max_SE_Tot=np.max((FEASolve(env.VoidCheck,opts.Lx,opts.Ly,opts.Main_EX,opts.Main_EY,env.LC_Nodes,env.Load_Directions,env.BC_Nodes,Stress=True)[1]))\n",
    "    \n",
    "    \n",
    "def User_Inputs(env,opts):\n",
    "    '''When testing a trained agent, the user will be prompted to select\n",
    "    a single element to act as the loaded element, and two elements to act as the boundary \n",
    "    condition elements. Depending on where the elements are located, the nodes\n",
    "    corresponding to these elements will be selected'''\n",
    "    print(np.flip(np.reshape(range(0,(opts.Main_EX)*(opts.Main_EY)),(opts.Main_EX,opts.Main_EY)),0))\n",
    "    BC_Count=int(input('How many boundary elements would you like to have: '))\n",
    "    env.BC_Elements=[]\n",
    "    env.LC_Elements=[]\n",
    "    env.BC_Nodes=[]\n",
    "    env.LC_Nodes=[]\n",
    "    env.Load_Types=[]\n",
    "    env.Load_Directions=[]\n",
    "    for Counting in range(0,BC_Count):\n",
    "        env.BC_Elements=np.append(env.BC_Elements,int(input('Please select an element to apply Boundary condition #'+str(Counting+1)+': ')))\n",
    "        if env.BC_Elements[Counting]>(opts.Main_EX)*(opts.Main_EY) or env.BC_Elements[Counting]<0 or env.BC_Elements[Counting]!=int(env.BC_Elements[Counting]):\n",
    "            print('Code Terminated By User...')\n",
    "            sys.exit()\n",
    "    print(np.flip(np.reshape(range(0,(opts.Main_EX*opts.Main_EY)),(opts.Main_EX,opts.Main_EY)),0))\n",
    "    LC_Count=int(input('How many loading elements would you like to have: '))\n",
    "    \n",
    "\n",
    "    for Counting in range(0,LC_Count):\n",
    "        env.LC_Elements=np.append(env.LC_Elements,int(input('Please select an element to apply the load #'+str(Counting+1)+': ')))\n",
    "        if env.LC_Elements[Counting]>(opts.Main_EX)*(opts.Main_EY) or env.LC_Elements[Counting]<0 or env.LC_Elements[Counting]!=int(env.LC_Elements[Counting]):\n",
    "            print('Code Terminated By User...')\n",
    "            sys.exit()\n",
    "        env.Load_Types=np.append(env.Load_Types,int(input('Input 0 for a Vertical Load or Input 1 for a Horizontal load for this element: ')))\n",
    "        env.Load_Directions=np.append(env.Load_Directions,int(input('Input -1 for a tensile load or Input 1 for a compressive load for this element: ')))\n",
    "    for Counting in range(0,LC_Count):\n",
    "        if env.Load_Types[Counting]==0:\n",
    "            LC_New_Nodes=LC_Nodes(int(env.LC_Elements[Counting]),env.Load_Types[Counting],env.Load_Directions[Counting],env.Lx,env.Ly,env.EX,env.EY,Counting,Node_Location=True)\n",
    "            env.LC_Nodes=np.append(env.LC_Nodes,LC_New_Nodes[0]+(opts.Main_EX+1)*(opts.Main_EY+1))\n",
    "            env.LC_Nodes=np.append(env.LC_Nodes,LC_New_Nodes[1]+(opts.Main_EX+1)*(opts.Main_EY+1))\n",
    "        else:\n",
    "            LC_New_Nodes=LC_Nodes(int(env.LC_Elements[Counting]),env.Load_Types[Counting],env.Load_Directions[Counting],env.Lx,env.Ly,env.EX,env.EY,Counting,Node_Location=True)\n",
    "            env.LC_Nodes=np.append(env.LC_Nodes,LC_New_Nodes[0])\n",
    "            env.LC_Nodes=np.append(env.LC_Nodes,LC_New_Nodes[1])\n",
    "    for Counting in range(0,BC_Count):\n",
    "        env.BC_Nodes=np.append(env.BC_Nodes,BC_Nodes(int(env.BC_Elements[Counting]),env.Lx,env.Ly,env.EX,env.EY)[0])\n",
    "        env.BC_Nodes=np.append(env.BC_Nodes,BC_Nodes(int(env.BC_Elements[Counting]),env.Lx,env.Ly,env.EX,env.EY)[1])\n",
    "\n",
    "    env.LC_state=list(np.zeros((1,(opts.Main_EX)*(opts.Main_EY)))[0])\n",
    "    for LCS in range(0,len(env.LC_Elements)):\n",
    "                env.LC_state[int(env.LC_Elements[LCS])]=1\n",
    "    env.LC_state=np.reshape(env.LC_state,(opts.Main_EX,opts.Main_EY))\n",
    "    env.BC=[]\n",
    "    env.BC=np.append(env.BC,env.BC_Elements)\n",
    "    env.BC=np.append(env.BC,env.LC_Elements)\n",
    "    env.BC_state=list(np.zeros((1,(opts.Main_EX)*(opts.Main_EY)))[0])\n",
    "    for BCS in range(0,len(env.BC_Elements)):\n",
    "        env.BC_state[int(env.BC_Elements[BCS])]=1\n",
    "    env.BC_state=np.reshape(env.BC_state,(opts.Main_EX,opts.Main_EY))\n",
    "    env.Max_SE_Tot=np.max((FEASolve(env.VoidCheck,opts.Lx,opts.Ly,opts.Main_EX,opts.Main_EY,env.LC_Nodes,env.Load_Directions,env.BC_Nodes,Stress=True)[1]))\n",
    "    \n",
    "    return \n",
    "def Testing_Inputs(env,opts):\n",
    "    '''Every 200 episodes, the boundary and loading conditions\n",
    "    should be set as those of a cantilever beam to monitor the progress\n",
    "    of the agents learning'''\n",
    "    env.BC_Nodes=np.array([0,0,opts.Main_EX*opts.Main_EY,opts.Main_EX*opts.Main_EY])\n",
    "    env.LC_Nodes=np.array([opts.Main_EX+(opts.Main_EX+1)*(opts.Main_EY+1),opts.Main_EX-1+(opts.Main_EX)*(opts.Main_EY+1)])\n",
    "\n",
    "    env.LC_Elements=np.array([np.where(rectangularmesh(opts.Lx,opts.Ly,opts.Main_EX,opts.Main_EY)[1]==env.LC_Nodes[0]-((opts.Main_EX+1)*(opts.Main_EY+1)))[0][0]])\n",
    "    env.BC_Elements=[0,(opts.Main_EX)*(opts.Main_EY-1)]\n",
    "    env.LC_state=list(np.zeros((1,(opts.Main_EX)*(opts.Main_EY)))[0])\n",
    "    env.LC_state[env.LC_Elements[0]]=1\n",
    "    env.LC_state=np.reshape(env.LC_state,(opts.Main_EX,opts.Main_EY))\n",
    "    env.Load_Types=[0]\n",
    "    env.Load_Directions=[-1] #1 for Compressive Load, -1 for tensile load\n",
    "    env.BC=[]\n",
    "    env.BC=np.append(env.BC,env.BC_Elements)\n",
    "    env.BC=np.append(env.BC,env.LC_Elements)\n",
    "    env.BC_state=list(np.zeros((1,(opts.Main_EX)*(opts.Main_EY)))[0])\n",
    "    env.BC_state[env.BC_Elements[0]]=1\n",
    "    env.BC_state[env.BC_Elements[1]]=1\n",
    "    env.BC_state=np.reshape(env.BC_state,(opts.Main_EX,opts.Main_EY))\n",
    "    env.Max_SE_Tot=np.max((FEASolve(env.VoidCheck,opts.Lx,opts.Ly,opts.Main_EX,opts.Main_EY,env.LC_Nodes,env.Load_Directions,env.BC_Nodes,Stress=True)[1]))\n",
    "\n",
    "def Testing_Info(env,env_primer,env_primer2,opts,score,Progressive_Refinement,From_App,Fixed):\n",
    "    '''Function that outputs the results of a testing trial. The results include\n",
    "    the score based on the reward function, the final strain energy, and if needed\n",
    "    the number of arbitrary blocks removed by the shaving algorithm'''\n",
    "    if not From_App:\n",
    "        import matplotlib.pyplot as plt\n",
    "        print('----------------')\n",
    "    \n",
    "        print('The final topology: ')\n",
    "        for BC_Count in range(0,len(env.BC_Elements)):\n",
    "            print('BC Element #'+str(BC_Count)+': '+str(int(env.BC_Elements[BC_Count])))\n",
    "        for LC_Count in range(0,len(env.LC_Elements)):\n",
    "            print('LC Element #'+str(LC_Count)+': '+str(int(env.LC_Elements[LC_Count])))\n",
    "            if env.Load_Types[LC_Count]==0:\n",
    "                Load_Types='Vertical'\n",
    "            else:\n",
    "                Load_Types='Horizontal'\n",
    "            if env.Load_Directions[LC_Count]==-1:\n",
    "                Load_Dir='Tensile'\n",
    "            else:\n",
    "                Load_Dir='Compressive'\n",
    "            print('Load Type: '+Load_Dir)\n",
    "            print('Load Direction: '+Load_Types)\n",
    "      \n",
    "        if Progressive_Refinement:\n",
    "            env_primer.render()\n",
    "            env_primer2.render()\n",
    "        env.render()\n",
    "        Final_Results=FEASolve(list(env.VoidCheck),opts.Lx,opts.Ly,opts.Main_EX,opts.Main_EY,env.LC_Nodes,env.Load_Directions,env.BC_Nodes,Stress=True)\n",
    "        print('Strain Energy for Final Topology: '+str(round(np.max(Final_Results[1]),1)))\n",
    "        p=opts.P_Norm\n",
    "        print('Maximum P_Norm Stress Perc Increase: '+str(round(1-(env.P_Norm/sum(sum([number**p for number in np.reshape(Final_Results[2],(1,env.EX*env.EY))]))**(1/p)),2)))\n",
    "        print('Final Volume Fraction: '+str(round(1-(list(env.VoidCheck).count(0)/(env.EX*env.EY)),3)))\n",
    "        \n",
    "        print('----------------')\n",
    "        Mat_Plot=copy.deepcopy(env_primer.VoidCheck)\n",
    "        plt.figure(1)\n",
    "        for BC_Count in range(0,len(env_primer.BC_Elements)):\n",
    "            Mat_Plot[int(env_primer.BC_Elements[BC_Count])]=3\n",
    "        for LC_Count in range(0,len(env_primer.LC_Elements)):\n",
    "            Mat_Plot[int(env_primer.LC_Elements[LC_Count])]=2\n",
    "        plt.subplot(221)\n",
    "        plt.imshow(np.flip(np.reshape(Mat_Plot,(opts.PR_EX,opts.PR_EY)),axis=0),cmap='Blues')\n",
    "        Mat_Plot=copy.deepcopy(env_primer2.VoidCheck)\n",
    "        for BC_Count in range(0,len(env_primer2.BC_Elements)):\n",
    "            Mat_Plot[int(env_primer2.BC_Elements[BC_Count])]=3\n",
    "        for LC_Count in range(0,len(env_primer2.LC_Elements)):\n",
    "            Mat_Plot[int(env_primer2.LC_Elements[LC_Count])]=2\n",
    "            plt.subplot(222)\n",
    "        plt.imshow(np.flip(np.reshape(Mat_Plot,(opts.PR2_EX,opts.PR2_EY)),axis=0),cmap='Blues')\n",
    "        Mat_Plot=copy.deepcopy(env.VoidCheck)\n",
    "        for BC_Count in range(0,len(env.BC_Elements)):\n",
    "            Mat_Plot[int(env.BC_Elements[BC_Count])]=3\n",
    "        for LC_Count in range(0,len(env.LC_Elements)):\n",
    "            Mat_Plot[int(env.LC_Elements[LC_Count])]=2\n",
    "        plt.subplot(224)\n",
    "        plt.imshow(np.flip(np.reshape(Mat_Plot,(opts.Main_EX,opts.Main_EY)),axis=0),cmap='Blues')\n",
    "        plt.show()\n",
    "        App_Plot={}\n",
    "    else:\n",
    "        Mat_Plot=copy.deepcopy(env.VoidCheck)\n",
    "        App_Plot={}\n",
    "        App_Plot['Topology']=[]\n",
    "        App_Plot['SE']=[]\n",
    "        App_Plot['VF']=[]\n",
    "        App_Plot['Topology'].append([str(x) for x in Mat_Plot])\n",
    "        App_Plot['SE'].append(str(round(env.Max_SE_Ep,1)))\n",
    "        App_Plot['VF'].append(str(round(1-(list(env.VoidCheck).count(0)/(env.EX*env.EY)),3)))\n",
    "    return App_Plot\n",
    "        \n",
    "def poly_matrix(x, y, order=2):\n",
    "    \"\"\" Function to produce a matrix built on a quadratic surface \"\"\"\n",
    "    ncols = (order + 1)**2\n",
    "    G = np.zeros((x.size, ncols))\n",
    "    ij = itertools.product(range(order+1), range(order+1))\n",
    "    for k, (i, j) in enumerate(ij):\n",
    "        G[:, k] = x**i * y**j\n",
    "    return G   \n",
    "\n",
    "def Reward_Surface(opts):\n",
    "    x=np.array([1,0,0,1,.5,0,.5])\n",
    "    y=np.array([0,0,1,1,.5,.5,0])\n",
    "    z=np.array([])\n",
    "    a=opts.a\n",
    "    b=opts.b\n",
    "    for i in range(0,len(x)):\n",
    "        z=np.append(z,(a*(x[i])**2)+(b*(y[i])**2))\n",
    "    \n",
    "    ordr=2\n",
    "    G = poly_matrix(x, y, ordr)\n",
    "    # Solve for np.dot(G, m) = z:\n",
    "    m = np.linalg.lstsq(G, z,rcond=None)[0]\n",
    "    nx, ny = 1000, 1000\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.linspace(0, 1, nx),\n",
    "                         np.linspace(0, 1, ny))\n",
    "    GoG = poly_matrix(xx.ravel(), yy.ravel(), ordr)\n",
    "    zz = np.reshape(np.dot(GoG, m), xx.shape)\n",
    "#     this_dir, this_filename = os.path.split(__file__)\n",
    "#     base_folder =this_dir\n",
    "    with open('./Trial_Data/Reward_Data.npy','rb') as f:\n",
    "        Data = np.load(f)\n",
    "    X_Data=Data[:,0]\n",
    "    Y_Data=Data[:,1]\n",
    "    Z_Data=Data[:,2]\n",
    "\n",
    "    GG = poly_matrix(X_Data, Y_Data, ordr)\n",
    "# Solve for np.dot(G, m) = z:\n",
    "    mm = np.linalg.lstsq(GG, Z_Data,rcond=None)[0]\n",
    "\n",
    "    GoGG = poly_matrix(xx.ravel(), yy.ravel(), ordr)\n",
    "    Reward_Ind = np.reshape(np.dot(GoGG, mm), xx.shape)[:,-1]\n",
    "    return zz,Reward_Ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60069a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38445bcc",
   "metadata": {},
   "source": [
    "# RL_NECESSITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0c614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 12 17:06:46 2021\n",
    "\n",
    "@author: nbrow\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam # (if keras version 2.3.1)\n",
    "from tensorflow.math import argmax\n",
    "import tensorflow.keras as keras \n",
    "from tensorflow.keras import layers,models \n",
    "import os\n",
    "\n",
    "os.environ[\"cuda_visible_devices\"]=\"1\"\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self,env,opts,Increase,n_actions,input_dims,epsilon,\n",
    "                 filename_save,filename_load,EX,EY):\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.n_actions=n_actions\n",
    "        self.gamma = opts.gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.EX=EX\n",
    "        self.EY=EY\n",
    "        self.env=env\n",
    "        self.eps_dec = opts.epsilon_dec\n",
    "        self.eps_min = opts.eps_end\n",
    "        self.replace = opts.replace\n",
    "        self.batch_size = opts.batch_size\n",
    "        self.lr=opts.lr\n",
    "        self.learn_step_counter = 0\n",
    "        self.memory = ReplayBuffer(opts.mem_size, input_dims)\n",
    "        self.q_eval = DuelingDeepQNetwork(self.EX*self.EY,Increase)\n",
    "        self.q_next = DuelingDeepQNetwork(self.EX*self.EY,Increase)\n",
    "#         this_dir, this_filename = os.path.split(__file__)\n",
    "        self.checkpoint_file_save='C:/Users/dabni/Desktop/TO/RL_topopt_KSME2023-ksme2023/Top_Opt_RL/DQN/DAB/NN_Weights/'+filename_save+'_NN_weights'\n",
    "        self.checkpoint_file_load='C:/Users/dabni/Desktop/TO/RL_topopt_KSME2023-ksme2023/Top_Opt_RL/DQN/DAB/NN_Weights/'+filename_load+'_NN_weights'\n",
    "        self.q_eval.compile(optimizer=Adam(learning_rate=self.lr),\n",
    "                            loss='mean_squared_error')\n",
    "        # just a formality, won't optimize network\n",
    "        self.q_next.compile(optimizer=Adam(learning_rate=self.lr),\n",
    "                            loss='mean_squared_error')\n",
    "\n",
    "    def store_transition(self, state, action, reward, new_state, done):\n",
    "        self.memory.store_transition(state, action, reward, new_state, done)\n",
    "\n",
    "    def choose_action(self, observation,load_checkpoint,Testing):\n",
    "        self.action_space = [i for i in range(self.n_actions)]\n",
    "        if np.random.random() < self.epsilon and not load_checkpoint and not Testing:\n",
    "            Void=np.array(self.env.VoidCheck)\n",
    "            BC=np.array(np.reshape(self.env.BC_state,(1,(self.EX*self.EY))))\n",
    "            LC=np.array(np.reshape(self.env.LC_state,(1,(self.EX*self.EY))))\n",
    "            Clear_List=np.where(Void==0)[0]\n",
    "            BC_List=np.where(BC==1)[0]\n",
    "            LC_List=np.where(LC==1)[0]\n",
    "            self.action_space = [ele for ele in self.action_space if ele not in Clear_List]\n",
    "            self.action_space = [ele for ele in self.action_space if ele not in BC_List]\n",
    "            self.action_space = [ele for ele in self.action_space if ele not in LC_List]\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            state = observation\n",
    "            state=state.reshape(-1,self.EX,self.EY,3)\n",
    "            actions = self.q_eval.call(state)\n",
    "            action=argmax(actions, axis=1).numpy()[0]\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "\n",
    "        if self.memory.mem_cntr < self.batch_size:\n",
    "            Loss=.5\n",
    "            return Loss\n",
    "\n",
    "        if self.learn_step_counter % self.replace == 0 and self.learn_step_counter>0:\n",
    "            self.q_next.set_weights(self.q_eval.get_weights())  \n",
    "\n",
    "        states, actions, rewards, states_, dones = \\\n",
    "                                    self.memory.sample_buffer(self.batch_size)\n",
    "        q_pred = self.q_eval(states)\n",
    "        self.q_pred=q_pred\n",
    "        q_next = self.q_next(states_)\n",
    "        q_target = q_pred.numpy()\n",
    "        max_actions = argmax(self.q_eval(states_), axis=1)\n",
    "        # improve on my solution!\n",
    "        for idx, terminal in enumerate(dones):\n",
    "            #if terminal:\n",
    "                #q_next[idx] = 0.0\n",
    "            q_target[idx, actions[idx]] = rewards[idx] + \\\n",
    "                    self.gamma*q_next[idx, max_actions[idx]]*(1-int(dones[idx]))\n",
    "        self.q_target = q_target\n",
    "        Loss=np.subtract(q_target,q_pred.numpy())\n",
    "        Loss=np.square(Loss)\n",
    "        Loss=Loss.mean()\n",
    "        self.q_eval.train_on_batch(states, q_target)\n",
    "\n",
    "        self.epsilon = self.epsilon - self.eps_dec if self.epsilon > \\\n",
    "                        self.eps_min else self.eps_min \n",
    "\n",
    "        self.learn_step_counter += 1\n",
    "        if self.learn_step_counter>5000:\n",
    "            self.lr=2.5e-3\n",
    "        if self.learn_step_counter>7500:\n",
    "            self.lr=1e-3\n",
    "        return Loss\n",
    "        \n",
    "    def save_models(self):\n",
    "        print('... saving models ...')\n",
    "        self.q_eval.save_weights(self.checkpoint_file_save)\n",
    "\n",
    "    def load_models(self):\n",
    "        print('... loading models ...')\n",
    "        self.q_eval.load_weights(self.checkpoint_file_load).expect_partial()\n",
    "        \n",
    "class DuelingDeepQNetwork(keras.Model):\n",
    "    def __init__(self, n_actions,Increase):\n",
    "        super(DuelingDeepQNetwork, self).__init__()\n",
    "        self.model = models.Sequential()\n",
    "\n",
    "        self.model.add(layers.Conv2D(16,(3,3),padding='same',activation='relu'))\n",
    "        self.model.add(layers.Conv2D(8,(3,3),padding='same',activation='relu'))\n",
    "        self.model.add(layers.Conv2D(4,(3,3),padding='same',activation='relu'))\n",
    "        self.model.add(layers.Conv2D(1,(3,3),padding='same',activation='relu'))\n",
    "        self.model.add(layers.Flatten())\n",
    "    \n",
    "    def call(self, state):\n",
    "        x = self.model(state)\n",
    "    \n",
    "        #V = self.model_V(x)\n",
    "        #A = self.model_A(x)\n",
    "        \n",
    "        Q = x#V + (A - tf.math.reduce_mean(A, axis=1, keepdims=True))\n",
    "        return Q\n",
    "    \n",
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size, input_shape):\n",
    "        self.mem_size = max_size\n",
    "        self.mem_cntr = 0\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_shape),\n",
    "                                        dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_shape),\n",
    "                                        dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, done):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.action_memory[index] = action\n",
    "        self.reward_memory[index] = reward\n",
    "        self.terminal_memory[index] = done\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "        batch = np.random.choice(max_mem, batch_size, replace=False)\n",
    "        states = self.state_memory[batch]\n",
    "        new_states = self.new_state_memory[batch]\n",
    "        actions = self.action_memory[batch]\n",
    "        rewards = self.reward_memory[batch]\n",
    "        dones = self.terminal_memory[batch]\n",
    "\n",
    "        return states, actions, rewards, new_states, dones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8e00e",
   "metadata": {},
   "source": [
    "# PLOT_LAYOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Plot the layout of the structure\n",
    "input: 1. file_name (string, the name of the json file, e.g. 'App_Data.json')\n",
    "       2. number of elements (tuple, e.g. (24,24))\n",
    "       3. save_name (string, the name of the saved image, e.g. 'result.jpg')\n",
    "'''\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_layout(file_name = 'App_Data.json', number_of_elements = (24, 24), save_name = 'result.jpg'):\n",
    "    with open(file_name) as file:\n",
    "        datas = json.load(file)\n",
    "        aa = datas[\"Topology\"]\n",
    "    \n",
    "    aa_sq = np.array(aa).squeeze().reshape(number_of_elements[0], number_of_elements[1])\n",
    "    aa_num = aa_sq.astype(np.float64)\n",
    "    aa_num = np.int64(aa_num)\n",
    "    \n",
    "    \n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.matshow(aa_num, cmap=plt.cm.Blues)\n",
    "#     for i in range(number_of_elements[0]):\n",
    "#         for j in range(number_of_elements[1]):\n",
    "#             c = aa_num[j,i]\n",
    "#             ax.text(i, j, str(c), va='center', ha='center')\n",
    "    plt.savefig(save_name, dpi=300)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf8115",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27526142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr  2 09:34:14 2021\n",
    "\n",
    "@author: nbrow\n",
    "@modified for primary mirror application \n",
    "\"\"\"\n",
    "\n",
    "''' Nathan Brown \n",
    "Main Function for the Reinforcement Learning Based Topology Optimization Solver using Double Q-Learning'''\n",
    "import os, sys\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname(os.path.abspath(os.path.dirname(\"TOPRL\"))))))\n",
    "# import FEA_SOLVER_GENERAL\n",
    "# from Top_Opt_RL.DQN.FEA_SOLVER_GENERAL import *\n",
    "# from FEA_SOLVER_GENERAL import *\n",
    "# from Top_Opt_RL.DQN.FEA_SOLVER_GENERAL import FEA_SOLVER_GENERAL\n",
    "\n",
    "# from Top_Opt_RL.DQN.opts import parse_opts\n",
    "# from Top_Opt_RL.DQN.TopOpt_Env_Functions import TopOpt_Gen, Prog_Refine_Act,User_Inputs,App_Inputs, Testing_Inputs, Testing_Info, Min_Dist_Calc  \n",
    "# from Top_Opt_RL.DQN.Matrix_Transforms import obs_flip, action_flip, Mesh_Transform, Mesh_Triming \n",
    "# from Top_Opt_RL.DQN.RL_Necessities import Agent \n",
    "def plot_learning_curve(x, scores, figure_file):\n",
    "    import matplotlib.pyplot as plt\n",
    "    running_avg = np.zeros(len(scores))\n",
    "    for i in range(len(running_avg)):\n",
    "        running_avg[i] = np.mean(scores[max(0, i-50):(i+1)])\n",
    "    plt.plot(x, running_avg)\n",
    "    plt.title('Running average of previous 100 scores')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel(' Average Reward')\n",
    "    plt.savefig(figure_file)\n",
    "def Data_History(score_history, per_history, succ_history, Loss_history, Total_Loss, score, Main_EX, Main_EY,i):\n",
    "\n",
    "    Loss_history.append(Total_Loss)\n",
    "    avg_Loss=np.mean(Loss_history[-50:])\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-50:])\n",
    "    Succ_Steps=list(env.VoidCheck).count(0)\n",
    "    succ_history.append(Succ_Steps)\n",
    "\n",
    "    avg_succ = np.mean(succ_history[-50:])\n",
    "    Percent_Succ=Succ_Steps/(Main_EX*Main_EY)\n",
    "    per_history.append(Percent_Succ)\n",
    "    avg_percent=np.mean(per_history[-50:])\n",
    "    return score_history,per_history,succ_history,Loss_history,Succ_Steps,Percent_Succ,avg_succ,avg_score,avg_Loss,avg_percent\n",
    "\n",
    "def TopOpt_Designing(User_Conditions, opts, envs): #,my_call_back_functions):\n",
    "    Time_Trial = opts.Time_Trial\n",
    "    if opts.Progressive_Refinement:\n",
    "        agent_primer= Agent(envs.env_primer,opts,Increase=False,filename_save=opts.filename_save+str(opts.PR_EX)+'by'+str(opts.PR_EY),\n",
    "                            filename_load=opts.filename_load,EX=opts.PR_EX,EY=opts.PR_EY, n_actions=opts.PR_EX*opts.PR_EY,\n",
    "                            epsilon=0,input_dims=[opts.PR_EX,opts.PR_EY,3])\n",
    "                            \n",
    "        agent_primer2= Agent(envs.env_primer2,opts,Increase=False,filename_save=opts.filename_save+str(opts.PR2_EX)+'by'+str(opts.PR2_EY),\n",
    "                            filename_load=opts.filename_load,EX=opts.PR2_EX,EY=opts.PR2_EY, n_actions=opts.PR2_EX*opts.PR2_EY, \n",
    "                            epsilon=0,input_dims=[opts.PR2_EX,opts.PR2_EY,3])\n",
    "        agent_primer.load_models()\n",
    "        agent_primer2.load_models()\n",
    "    \n",
    "    agent = Agent(envs.env,opts,Increase=False,filename_save=opts.filename_save+str(opts.Main_EX)+'by'+str(opts.Main_EY),\n",
    "                  filename_load=opts.filename_load,EX=opts.Main_EX,EY=opts.Main_EY, n_actions=opts.Main_EX*opts.Main_EY, \n",
    "                  epsilon=1.0, input_dims=[opts.Main_EX,opts.Main_EY,3])\n",
    "    if opts.Load_Checkpoints: agent.load_models()    \n",
    "    figure_file = 'plots/' + opts.filename_save +'_reward.png'    \n",
    "    best_score = envs.env.reward_range[0]    \n",
    "    score_history ,per_history,succ_history,Loss_history= [],[],[],[]\n",
    "    \n",
    "    if not opts.Load_Checkpoints:\n",
    "        from pandas import DataFrame \n",
    "        TrialData=DataFrame(columns=['Episode','Reward','Successfull Steps','Percent Successful','Avg Loss','SDEV','Epsilon','Time'])\n",
    "    envs.env.reset_conditions()\n",
    "    if opts.From_App:  opts.n_games=1\n",
    "    for i in range(opts.n_games):\n",
    "        Testing = False #Used to render the environment and track learning of the agent \n",
    "        if opts.Load_Checkpoints:\n",
    "            'If the user wants to test the agent, the user will be prompted to input BC and LC elements'\n",
    "            if opts.From_App:  App_Inputs(envs.env,envs.env_primer,envs.env_primer2,opts,User_Conditions)\n",
    "\n",
    "            else:  User_Inputs(envs.env,opts)\n",
    "\n",
    "        done = False\n",
    "        score = 0    \n",
    "        if i%10==0 and i>=100:\n",
    "            Testing=True\n",
    "            if i%200==0:\n",
    "                'Every 200 episodes, a special BC/LC will be used for monitoring purposes'\n",
    "                Testing_Inputs(envs.env,opts)\n",
    "                print('--------Testing Run------')\n",
    "        envs.env.VoidCheck=list(np.ones((1,envs.env.EX*envs.env.EY))[0])\n",
    "        if Time_Trial:     Start_Time_Trial=time.perf_counter()\n",
    "        observation = envs.env.reset()\n",
    "        print(envs.env)\n",
    "        if opts.Progressive_Refinement:\n",
    "            ''' Set Up to Complete 3 Iterations of Progressive Refinement'''\n",
    "            #Progressive Refinement #1 Going from Smallest to Intermediate Mesh Size\n",
    "            envs.env_primer.VoidCheck=list(np.ones((1,envs.env_primer.EX*envs.env_primer.EY))[0])\n",
    "            Prog_Refine_Act(agent_primer,envs.env,envs.env_primer,opts.Load_Checkpoints,Testing,opts,opts.PR_EX,opts.PR_EY,Time_Trial,opts.From_App,FEA_Skip=1)\n",
    "            #Progressive Refinement #2 Going for Intermediate to Final Mesh Size\n",
    "            envs.env_primer2.VoidCheck=Mesh_Transform(opts.PR_EX,opts.PR_EY,opts.PR2_EX,opts.PR2_EY,envs.env_primer.VoidCheck)\n",
    "            if opts.From_App:\n",
    "                del agent_primer\n",
    "            Prog_Refine_Act(agent_primer2,envs.env,envs.env_primer2,opts.Load_Checkpoints,Testing,opts,opts.PR2_EX,opts.PR2_EY,Time_Trial,opts.From_App,FEA_Skip=1)\n",
    "            #This outcome will now be used as the final mesh Size \n",
    "            envs.env.VoidCheck=Mesh_Transform(opts.PR2_EX,opts.PR2_EY,opts.Main_EX,opts.Main_EY,envs.env_primer2.VoidCheck)\n",
    "            if opts.From_App:\n",
    "                del agent_primer2\n",
    "            #Removed_Num=Mesh_Triming(env_primer,PR_EX,PR_EY)\n",
    "            #Uncomment the above line if you want to incorporate mesh trimming\n",
    "\n",
    "            observation[:,:,0]=np.reshape(FEASolve(envs.env.VoidCheck,opts.Lx,opts.Ly,opts.Main_EX,opts.Main_EY,envs.env.LC_Nodes,envs.env.Load_Directions,envs.env.BC_Nodes,Stress=True)[3],(opts.Main_EX,opts.Main_EY))\n",
    "        observation_v, observation_h,observation_vh=obs_flip(observation,opts.Main_EX,opts.Main_EY)\n",
    "        Last_Reward=0\n",
    "        while not done:\n",
    "            if i%1000==0 and i>=1: #Every 1000 iterations, show the activation maps\n",
    "                from keract import get_activations, display_activations \n",
    "                activations = get_activations(agent.q_eval.model, observation.reshape(-1,opts.Main_EX,opts.Main_EY,3))\n",
    "                display_activations(activations, save=False)\n",
    "            action = agent.choose_action(observation,opts.Load_Checkpoints,Testing)\n",
    "            observation_, reward, done, It= envs.env.step(action,observation,Last_Reward,opts.Load_Checkpoints,envs.env,FEA_Skip=1,PR=False)\n",
    "            if not opts.Load_Checkpoints:\n",
    "                observation_v_,observation_h_,observation_vh_=obs_flip(observation_,opts.Main_EX,opts.Main_EY)\n",
    "                action_v,action_h,action_vh=action_flip(action,opts.Main_EX,opts.Main_EY)\n",
    "                agent.store_transition(observation,action,reward,observation_,done)\n",
    "                agent.store_transition(observation_v,action_v,reward,observation_v_,done)\n",
    "                agent.store_transition(observation_h,action_h,reward,observation_h_,done)\n",
    "                agent.store_transition(observation_vh,action_vh,reward,observation_vh_,done)\n",
    "            score += reward\n",
    "            App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)\n",
    "            # _=[fn(App_Plot) for fn in my_call_back_functions]\n",
    "            Last_Reward=reward\n",
    "            if Testing and not Time_Trial:\n",
    "                envs.env.render()\n",
    "                print('Current Score: '+str(round(score,3)))\n",
    "            observation = observation_\n",
    "            if not opts.Load_Checkpoints:\n",
    "                observation_v=observation_v_\n",
    "                observation_h=observation_h_\n",
    "                observation_vh=observation_vh_\n",
    "            if opts.Load_Checkpoints and not Time_Trial:   envs.env.render()\n",
    "        App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)\n",
    "        # _=[fn(App_Plot) for fn in my_call_back_functions]\n",
    "        return App_Plot        \n",
    "        toc=time.perf_counter()\n",
    "\n",
    "        if Time_Trial and not opts.From_App:\n",
    "            print('It took '+str(round(toc-Start_Time_Trial,1))+' seconds to complete this time trial.')    \n",
    "\n",
    "        App_Plot=Testing_Info(envs.env,envs.env_primer,envs.env_primer2,opts,score,opts.Progressive_Refinement,opts.From_App,Fixed=True)\n",
    "class EnviromentsRL:\n",
    "    def __init__(self, opts):\n",
    "        if opts.Load_Checkpoints:\n",
    "            SC=opts.SC\n",
    "            if opts.VF_S==0 and opts.From_App: #If the user wants to set a final volume fraction, set the intermediate volume fractions accordingly\n",
    "                Vol_Frac_2=opts.Vol_Frac_2\n",
    "                Vol_Frac_1=opts.Vol_Frac_1\n",
    "                Vol_Frac_3=opts.Vol_Frac_3 \n",
    "        else:\n",
    "            Vol_Frac_3=opts.Vol_Frac_3\n",
    "            Vol_Frac_1=opts.Vol_Frac_1\n",
    "            Vol_Frac_2=opts.Vol_Frac_2\n",
    "        self.env = TopOpt_Gen(opts.Main_EX,opts.Main_EY,Vol_Frac_3,SC,opts)\n",
    "        self.env_primer= TopOpt_Gen(opts.PR_EX,opts.PR_EY,Vol_Frac_1,SC,opts)\n",
    "        self.env_primer2=TopOpt_Gen(opts.PR2_EX,opts.PR2_EY,Vol_Frac_2,SC,opts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00deb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Class for Topology Optimization Options\n",
    "# MAIN / PR2 한 만큼 각져짐 \n",
    "'''\n",
    "class Top_Options:\n",
    "    def __init__(self, Main_EX=48, Main_EY=48, PR2_EX=24, PR2_EY=24, PR_EX=3, PR_EY=3, Lx=1, Ly=1, Eta=2, a=5, b=5, replace=100, epsilon_dec=3.5e-4, eps_end=0.01, mem_size=30000, n_games=50000, batch_size=128, lr=5e-3, gamma=0.1, Vol_Frac_1=0.7, Vol_Frac_2=0.5, Vol_Frac_3=0.25, SC=10, P_Norm=10, filename_save='DDQN_TopOpt_Generalized_CNN_4L', filename_load='DDQN_TopOpt_Generalized_CNN_4L_6by6', Progressive_Refinement=True, LC=False, Load_Checkpoints=True, VF_S=0, Min_Dist=0, Time_Trial=True, configfile='config.json', From_App=True, base_folder=\".\"):\n",
    "        self.Main_EX = Main_EX  # Number of X Elements for Larger Environment\n",
    "        self.Main_EY = Main_EY  # Number of Y Elements for Larger Environment\n",
    "        self.PR2_EX = PR2_EX  # Number of X Elements for Second Environment used in Case of Progressive Refinement\n",
    "        self.PR2_EY = PR2_EY  # Number of Y Elements for Second Environment used in Case of Progressive Refinement\n",
    "        self.PR_EX = PR_EX  # Number of X Elements for Smaller Environment used in Case of Progressive Refinement\n",
    "        self.PR_EY = PR_EY  # Number of Y Elements for Smaller Environment used in Case of Progressive Refinement\n",
    "        self.Lx = Lx  # Length of the Structure in the X Direction\n",
    "        self.Ly = Ly  # Length of the Structure in the Y Direction\n",
    "        self.Eta = Eta  # Used for dynamic adjusting reward function. Larger eta means less prevalence given towards changes between current and previous reward. Recommend using [2,4]\n",
    "        self.a = a  # X Coefficient of the Quadratic Reward Surface\n",
    "        self.b = b  # Y Coefficient of the Quadratic Reward Surface\n",
    "        self.replace = replace  # Number of iterations between switching the weights from the active network to the target network\n",
    "        self.epsilon_dec = epsilon_dec  # Iterative decay amount of the epsilon value used for exploration/explotation\n",
    "        self.eps_end = eps_end  # Smallest Allowable Epsilon value to be used for exploration/explotation\n",
    "        self.mem_size = mem_size  # Size of the Replay Buffer\n",
    "        self.n_games = n_games  # Maximum Number of Training Episodes Conducted\n",
    "        self.batch_size = batch_size  # Batch Size that will be taken from the Replay Buffer per training episode\n",
    "        self.lr = lr  # Starting Learning Rate for the Network\n",
    "        self.gamma = gamma  # Discount Factor for Future Rewards\n",
    "        self.Vol_Frac_1 = Vol_Frac_1  # Volume Fraction during first progressive refinement\n",
    "        self.Vol_Frac_2 = Vol_Frac_2  # Final Volume Fraction\n",
    "        self.Vol_Frac_3 = Vol_Frac_3  # Final Volume Fraction\n",
    "        self.SC = SC  # Stress constraint, between 0 and 2\n",
    "        self.P_Norm = P_Norm  # Smoothing Parameter for P-Norm Global Stress calculation\n",
    "        self.filename_save = filename_save  # When training, what name would you like your weights, and figure saved as\n",
    "        self.filename_load = filename_load  # When testing, what name is your NN weights saved under\n",
    "        self.Progressive_Refinement = Progressive_Refinement\n",
    "        self.LC = LC # type in loading conditions manually\n",
    "        self.Load_Checkpoints = Load_Checkpoints\n",
    "        self.VF_S = VF_S # Use vol fraction constraint [0] or stress constraint [1]\n",
    "        self.Min_Dist = Min_Dist # The 0 value serves as a place holder to represent the minimum distance between the bounded and loaded elements in a given load case\n",
    "        self.Time_Trial = Time_Trial # Perform Time Trial\n",
    "        self.configfile = configfile # name of config file. \n",
    "        self.From_App = From_App # True if being called by an external app. Not sure this is needed. \"\n",
    "        self.base_folder = base_folder # Folder where to find saved files. Helpful if not running the app from the main folder. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Top_Options()\n",
    "opts.configfile = \".json\"\n",
    "User_Conditions = json.load(open(opts.configfile) ) if opts.From_App else None  \n",
    "envs = EnviromentsRL(opts)  \n",
    "App_Plot=TopOpt_Designing(User_Conditions,opts, envs)\n",
    "json.dump( App_Plot, open( \"App_Data.json\", 'w' ) )\n",
    "plot_layout(file_name='App_Data.json', number_of_elements=(opts.Main_EX, opts.Main_EY), save_name='App_Plot.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9a1dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "rltop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
